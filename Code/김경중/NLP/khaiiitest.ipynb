{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "khaiiitest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrym02kT+WfvETF0TY0wO6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4AFNN_gF-ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69eec3e5-3bd7-45db-ba9a-bc7a3a7e255e"
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "\n",
        "!pip install cmake\n",
        "\n",
        "!mkdir build\n",
        "\n",
        "!cd build && cmake /content/khaiii\n",
        "\n",
        "!cd /content/build/ && make all\n",
        "\n",
        "!cd /content/build/ && make resource\n",
        "\n",
        "!cd /content/build && make install\n",
        "\n",
        "!cd /content/build && make package_python\n",
        "\n",
        "!pip install /content/build/package_python\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'khaiii' already exists and is not an empty directory.\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "-- [khaiii] fused multiply add option enabled\n",
            "-- [hunter] Calculating Toolchain-SHA1\n",
            "-- [hunter] Calculating Config-SHA1\n",
            "-- [hunter] HUNTER_ROOT: /root/.hunter\n",
            "-- [hunter] [ Hunter-ID: 70287b1 | Toolchain-ID: 02ccb06 | Config-ID: dffbc08 ]\n",
            "-- [hunter] BOOST_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 1.68.0-p1)\n",
            "-- Boost version: 1.68.0\n",
            "-- [hunter] CXXOPTS_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 2.1.1-pre)\n",
            "-- [hunter] EIGEN_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 3.3.5)\n",
            "-- [hunter] FMT_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 4.1.0)\n",
            "-- [hunter] GTEST_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 1.8.0-hunter-p11)\n",
            "-- [hunter] NLOHMANN_JSON_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 3.3.0)\n",
            "-- [hunter] SPDLOG_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 0.16.3-p1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/build\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "Built target resource\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Up-to-date: /usr/local/include/khaiii\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_dev.h\n",
            "-- Up-to-date: /usr/local/include/khaiii/KhaiiiApi.hpp\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_api.h\n",
            "-- Up-to-date: /usr/local/share/khaiii\n",
            "-- Up-to-date: /usr/local/share/khaiii/config.json\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.key\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/embed.bin\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.one\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.4.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.len\n",
            "-- Up-to-date: /usr/local/share/khaiii/cnv2hdn.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.3.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.5.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/hdn2tag.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.2.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.val\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0.4\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so\n",
            "-- Up-to-date: /usr/local/bin/khaiii\n",
            "\u001b[36mRun CPack packaging tool for source...\u001b[0m\n",
            "CPack: Create package using ZIP\n",
            "CPack: Install projects\n",
            "CPack: - Install directory: /content/khaiii\n",
            "CPack: Create package\n",
            "CPack: - package: /content/build/khaiii-0.4.zip generated.\n",
            "Built target package_python\n",
            "Processing ./build/package_python\n",
            "Building wheels for collected packages: khaiii\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS89tSSfGDIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from khaiii import KhaiiiApi\n",
        "api = KhaiiiApi()\n",
        "for word in api.analyze(\"이거 되냐? 되ㅐ냐고\"):\n",
        "    for morph in word.morphs:\n",
        "        print(morph.lex)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upyCypBc-i3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#주요 참고 PyTorch로 시작하는 딥 러닝 입문, 유원준\n",
        "from torchtext import data  \n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7T1NhRtaV8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTcV2aB8URYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isAll0(x):\n",
        "    if type(x) == float:\n",
        "        return x\n",
        "    elif len(x) == x.count(' '):\n",
        "        return ''\n",
        "    else:\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C4BIvfK-e8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "\n",
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "\n",
        "\n",
        "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_df['document'] = train_df['document'].apply(isAll0)\n",
        "train_df['document'].replace('', np.nan, inplace=True)\n",
        "\n",
        "\n",
        "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_df['document'] = test_df['document'].apply(isAll0)\n",
        "test_df['document'].replace('', np.nan, inplace=True)\n",
        "\n",
        "\n",
        "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "\n",
        "train_df = train_df.dropna(how = 'any')\n",
        "test_df = test_df.dropna(how = 'any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU4xqF6e-uid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhuXSXriVmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EaPAX08WscC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulbculq9CpTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for i, row in train_df.iterrows():\n",
        "    val = row['document']\n",
        "    i += 1\n",
        "    if i % 10000 == 0:\n",
        "        print(i,\"/\",\"143660\")\n",
        "\n",
        "    temp = ['CLS']\n",
        "    for word in api.analyze(val):\n",
        "        for morph in word.morphs:\n",
        "            if morph.lex not in stopwords:\n",
        "                temp.append(morph.lex)\n",
        "    temp.append['SEP']\n",
        "    train_x.append(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx5Dv-cTXq4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvyyGGIX9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for i, row in test_df.iterrows():\n",
        "    val = row['document']\n",
        "    i += 1\n",
        "    if i % 10000 == 0:\n",
        "        print(i,\"/\",\"48000\")\n",
        "    temp = ['CLS']\n",
        "    \n",
        "    for word in api.analyze(val):\n",
        "        for morph in word.morphs:\n",
        "            if morph.lex not in stopwords:\n",
        "                temp.append(morph.lex)\n",
        "    temp.append['SEP']\n",
        "    test_x.append(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-38cBupadBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(vocab_size,oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "test_x = tokenizer.texts_to_sequences(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg29ed74jufk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = np.array(train_df['label'])\n",
        "test_y = np.array(test_df['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT19Xp2ekb7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(train_x) if len(sentence) < 1]\n",
        "drop_test = [index for index, sentence in enumerate(test_x) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOt8np65kePK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.delete(train_x, drop_train, axis=0)\n",
        "train_x = np.delete(train_y, drop_train, axis=0)\n",
        "print(len(train_x))\n",
        "print(len(train_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG8qVu8GkxBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = np.delete(test_x, drop_test, axis=0)\n",
        "test_y = np.delete(test_y, drop_test, axis=0)\n",
        "print(len(test_x))\n",
        "print(len(test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2YrA9wihWdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_len = 30\n",
        "train_x = pad_sequences(train_x, maxlen = pad_len)\n",
        "test_X = pad_sequences(test_x, maxlen = pad_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_K1YTZ2kZaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}