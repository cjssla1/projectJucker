{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "khaiiitest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUVHdnwtwfM72BQxItJLXk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4AFNN_gF-ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "292923c5-ed31-48bb-bf42-9f29790fca9a"
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "\n",
        "!pip install cmake\n",
        "\n",
        "!mkdir build\n",
        "\n",
        "!cd build && cmake /content/khaiii\n",
        "\n",
        "!cd /content/build/ && make all\n",
        "\n",
        "!cd /content/build/ && make resource\n",
        "\n",
        "!cd /content/build && make install\n",
        "\n",
        "!cd /content/build && make package_python\n",
        "\n",
        "!pip install /content/build/package_python\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'khaiii' already exists and is not an empty directory.\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "-- [khaiii] fused multiply add option enabled\n",
            "-- [hunter] Calculating Toolchain-SHA1\n",
            "-- [hunter] Calculating Config-SHA1\n",
            "-- [hunter] HUNTER_ROOT: /root/.hunter\n",
            "-- [hunter] [ Hunter-ID: 70287b1 | Toolchain-ID: 02ccb06 | Config-ID: dffbc08 ]\n",
            "-- [hunter] BOOST_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 1.68.0-p1)\n",
            "-- Boost version: 1.68.0\n",
            "-- [hunter] CXXOPTS_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 2.1.1-pre)\n",
            "-- [hunter] EIGEN_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 3.3.5)\n",
            "-- [hunter] FMT_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 4.1.0)\n",
            "-- [hunter] GTEST_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 1.8.0-hunter-p11)\n",
            "-- [hunter] NLOHMANN_JSON_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 3.3.0)\n",
            "-- [hunter] SPDLOG_ROOT: /root/.hunter/_Base/70287b1/02ccb06/dffbc08/Install (ver.: 0.16.3-p1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/build\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "Built target resource\n",
            "[ 65%] Built target obj_khaiii\n",
            "[ 69%] Built target khaiii\n",
            "[ 76%] Built target bin_khaiii\n",
            "[100%] Built target test_khaiii\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Up-to-date: /usr/local/include/khaiii\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_api.h\n",
            "-- Up-to-date: /usr/local/include/khaiii/KhaiiiApi.hpp\n",
            "-- Up-to-date: /usr/local/include/khaiii/khaiii_dev.h\n",
            "-- Up-to-date: /usr/local/share/khaiii\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.2.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/embed.bin\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.5.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.4.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/preanal.tri\n",
            "-- Up-to-date: /usr/local/share/khaiii/hdn2tag.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/cnv2hdn.lin\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.val\n",
            "-- Up-to-date: /usr/local/share/khaiii/errpatch.len\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.key\n",
            "-- Up-to-date: /usr/local/share/khaiii/config.json\n",
            "-- Up-to-date: /usr/local/share/khaiii/conv.3.fil\n",
            "-- Up-to-date: /usr/local/share/khaiii/restore.one\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0.4\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so.0\n",
            "-- Up-to-date: /usr/local/lib/libkhaiii.so\n",
            "-- Up-to-date: /usr/local/bin/khaiii\n",
            "\u001b[36mRun CPack packaging tool for source...\u001b[0m\n",
            "CPack: Create package using ZIP\n",
            "CPack: Install projects\n",
            "CPack: - Install directory: /content/khaiii\n",
            "CPack: Create package\n",
            "CPack: - package: /content/build/khaiii-0.4.zip generated.\n",
            "Built target package_python\n",
            "Processing ./build/package_python\n",
            "Building wheels for collected packages: khaiii\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS89tSSfGDIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from khaiii import KhaiiiApi\n",
        "api = KhaiiiApi()\n",
        "for word in api.analyze(\"이거 되냐? 되ㅐ냐고\"):\n",
        "    for morph in word.morphs:\n",
        "        print(morph.lex)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upyCypBc-i3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#주요 참고 PyTorch로 시작하는 딥 러닝 입문, 유원준\n",
        "from torchtext import data  \n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7T1NhRtaV8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTcV2aB8URYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isAll0(x):\n",
        "    if type(x) == float:\n",
        "        return x\n",
        "    elif len(x) == x.count(' '):\n",
        "        return ''\n",
        "    else:\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C4BIvfK-e8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "\n",
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "\n",
        "\n",
        "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_df['document'] = train_df['document'].apply(isAll0)\n",
        "train_df['document'].replace('', np.nan, inplace=True)\n",
        "\n",
        "\n",
        "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_df['document'] = test_df['document'].apply(isAll0)\n",
        "test_df['document'].replace('', np.nan, inplace=True)\n",
        "\n",
        "\n",
        "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "\n",
        "train_df = train_df.dropna(how = 'any')\n",
        "test_df = test_df.dropna(how = 'any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU4xqF6e-uid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhuXSXriVmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EaPAX08WscC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulbculq9CpTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 0\n",
        "for i, row in train_df.iterrows():\n",
        "    val = row['document']\n",
        "    j += 1\n",
        "    if j % 10000 == 0:\n",
        "        print(i,\"/\",\"143660\")\n",
        "\n",
        "    temp = ['CLS']\n",
        "    for word in api.analyze(val):\n",
        "        for morph in word.morphs:\n",
        "            if morph.lex not in stopwords:\n",
        "                temp.append(morph.lex)\n",
        "    temp.append('SEP')\n",
        "    train_x.append(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx5Dv-cTXq4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvyyGGIX9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 0\n",
        "for i, row in test_df.iterrows():\n",
        "    val = row['document']\n",
        "    j += 1\n",
        "    if i % 10000 == 0:\n",
        "        print(j,\"/\",\"48000\")\n",
        "    temp = ['CLS']\n",
        "    \n",
        "    for word in api.analyze(val):\n",
        "        for morph in word.morphs:\n",
        "            if morph.lex not in stopwords:\n",
        "                temp.append(morph.lex)\n",
        "    temp.append('SEP')\n",
        "    test_x.append(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-38cBupadBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(vocab_size,oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "test_x = tokenizer.texts_to_sequences(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg29ed74jufk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = np.array(train_df['label'])\n",
        "test_y = np.array(test_df['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT19Xp2ekb7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(train_x) if len(sentence) < 1]\n",
        "drop_test = [index for index, sentence in enumerate(test_x) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOt8np65kePK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.delete(train_x, drop_train, axis=0)\n",
        "train_y = np.delete(train_y, drop_train, axis=0)\n",
        "print(len(train_x))\n",
        "print(len(train_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG8qVu8GkxBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = np.delete(test_x, drop_test, axis=0)\n",
        "test_y = np.delete(test_y, drop_test, axis=0)\n",
        "print(len(test_x))\n",
        "print(len(test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeApp2V8rR6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2YrA9wihWdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_len = 30\n",
        "train_x = pad_sequences(train_x, maxlen = pad_len,padding='post')\n",
        "test_x = pad_sequences(test_x, maxlen = pad_len,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_K1YTZ2kZaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_x)\n",
        "print(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THeBVw9LV1GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class nlp_dataset(Dataset):\n",
        "    def __init__(self,x,y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.FloatTensor(self.x[idx])\n",
        "        y = torch.FloatTensor(self.y[idx])\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zoRdBSmXj5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class grubase(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grubase, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        self.gru2 = nn.GRU(self.hidden_dim*2, self.hidden_dim, self.num_layers,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = x[:,-1,:]\n",
        "        x = self.norm(x)\n",
        "        #x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        #x = self.sigmoid(x).squeeze()\n",
        "        return x.squeeze()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRES7llXmMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function,train_loader,DEVICE):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x, y = batch\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkFcl9jlXnKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getF1(y_pred,y,threshold=0.5):\n",
        "    \n",
        "    yp = [1 if x > threshold else 0 for x in y_pred]\n",
        "\n",
        "    pp = 0\n",
        "    pf = 0\n",
        "    fp = 0\n",
        "    ff = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] > threshold:\n",
        "            if yp[i] > threshold: pp += 1\n",
        "            else: pf += 1\n",
        "        else:\n",
        "            if yp[i] < threshold: ff += 1\n",
        "            else: fp += 1\n",
        "\n",
        "    precision = pp / (pp + fp + 1e-5) \n",
        "    recall = pp / (pp + ff + 1e-5)\n",
        "    F1 = 2 * precision * recall / (precision + recall + 1e-5)\n",
        "    acc = (pp + ff) / (len(y) + 1e-5)\n",
        "    return F1, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUiJ0Y2JXoQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader, loss_function, DEVICE, batch_size, threshold):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_f1 = 0\n",
        "    total_acc = 0\n",
        "    for batch in val_loader:\n",
        "        x, y = batch\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        f1, acc = getF1(y_pred,y,threshold)\n",
        "        total_f1 += f1\n",
        "        total_acc += acc\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    size = len(val_loader) / batch_size\n",
        "    avg_loss = total_loss / size\n",
        "    avg_f1 = total_f1 / size\n",
        "    avg_acc = total_acc / size\n",
        "    return avg_loss, avg_f1, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeAESeh_Xqq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "batch_size = 256\n",
        "embed_dim = 128\n",
        "hidden_dim = 256\n",
        "dropout = 0.3\n",
        "layers = 1\n",
        "\n",
        "model = grubase(embed_dim,vocab_size+2,hidden_dim,layers,batch_size,dropout)\n",
        "model.to(device)\n",
        "loss = nn.BCEWithLogitsLoss(pos_weight = 1.1 * torch.ones([1])).to(device)\n",
        "lr = 0.003\n",
        "threshold = 0.5\n",
        "\n",
        "EPOCHS = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxzKLsBWXzv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = nlp_dataset(train_x,train_y)\n",
        "test_dataset = nlp_dataset(test_x,test_y)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size,True)\n",
        "val_loader = DataLoader(test_dataset,batch_size,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x17civFnmq-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in train_loader:\n",
        "    x, y = i\n",
        "    print(x,y)\n",
        "    print(len(x))\n",
        "    print(len(y))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHdz0RnOXtjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_val_f1 = 0\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, loss,train_loader,device)\n",
        "    val_loss,val_f1,val_acc = evaluate(model, val_loader, loss, device,batch_size,threshold)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %1.5f    val acc :%4.3f    F1 :%4.3f\" % (e, val_loss, val_acc,val_f1))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_f1 or val_f1 > best_val_f1:\n",
        "        print(\"Best saved\")\n",
        "        torch.save(model.state_dict(), '/content/gdrive/My Drive/GRUmodel/NLP_esemble_model.pt')\n",
        "        best_val_f1 = val_f1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}