{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reply_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1ujhiPtV3u8OY+iSX/qeD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg7kqHfy0j91",
        "outputId": "50623be7-642f-43eb-d7d5-b2c1f02ef5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install torch torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzcEzS306e4"
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "\n",
        "!pip install cmake\n",
        "\n",
        "!mkdir build\n",
        "\n",
        "!cd build && cmake /content/khaiii\n",
        "\n",
        "!cd /content/build/ && make all\n",
        "\n",
        "!cd /content/build/ && make resource\n",
        "\n",
        "!cd /content/build && make install\n",
        "\n",
        "!cd /content/build && make package_python\n",
        "\n",
        "!pip install /content/build/package_python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8p-Cep0uG6"
      },
      "source": [
        "\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "from copy import deepcopy # Add Deepcopy for args"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvaTFNuc0yZI",
        "outputId": "22c8f626-f094-4e36-d820-7f710c92a62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-7uTgUH9sm"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YDox5J425-4"
      },
      "source": [
        "#데이터 셋 간단하게\n",
        "class nlp_dataset(Dataset):\n",
        "    def __init__(self,x):\n",
        "        self.x = x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjOYzhOa1KVY"
      },
      "source": [
        "# 튜닝\n",
        "class grumodel(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grumodel, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        self.gru2 = nn.GRU(self.hidden_dim*2, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim*4,self.hidden_dim)\n",
        "        self.mlp2 = nn.Linear(self.hidden_dim,self.hidden_dim//4)\n",
        "        self.mlp3 = nn.Linear(self.hidden_dim//4,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp3(x)\n",
        "        return x.squeeze()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKbRX8h52gpo",
        "outputId": "3be5820d-351b-4419-aaaa-e8920991c708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "vocab_size = 6000\n",
        "pad_len = 30\n",
        "\n",
        "batch_size = 256\n",
        "embed_dim = 368\n",
        "hidden_dim = 512\n",
        "dropout = 0.7\n",
        "layers = 1\n",
        "\n",
        "model = grumodel(embed_dim,vocab_size,hidden_dim,layers,batch_size,dropout)\n",
        "modelPath = '/content/gdrive/My Drive/GRUmodel/Khaiii_gru_model.pt'\n",
        "model.load_state_dict(torch.load(modelPath))\n",
        "model.to(device)\n",
        "loss = nn.BCEWithLogitsLoss(pos_weight = 1.1 * torch.ones([1])).to(device)\n",
        "lr = 0.001\n",
        "threshold = 0.5\n",
        "\n",
        "EPOCHS = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "model.eval()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "grumodel(\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              "  (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (embed): Embedding(6000, 368)\n",
              "  (dropout): Dropout(p=0.7, inplace=False)\n",
              "  (gru): GRU(368, 512, batch_first=True, bidirectional=True)\n",
              "  (gru2): GRU(1024, 512, batch_first=True, bidirectional=True)\n",
              "  (mlp1): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (mlp2): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (mlp3): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er4bF2VBIsmW"
      },
      "source": [
        "#토크나이저 가져오기\n",
        "tokenizer = Tokenizer(vocab_size,oov_token = 'OOV')\n",
        "with open('/content/gdrive/My Drive/GRUmodel/tokenizer.json') as f:\n",
        "    data = json.load(f)\n",
        "    tokenizer = tokenizer_from_json(data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeNG3OdGBAfs"
      },
      "source": [
        "#불용어\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76YCj2CIAQNP"
      },
      "source": [
        "from khaiii import KhaiiiApi\n",
        "api = KhaiiiApi()\n",
        "#간단한 테스트\n",
        "\n",
        "temp = []\n",
        "for word in api.analyze(\"너무 재밌어요\"):\n",
        "    for morph in word.morphs:\n",
        "        if morph.lex not in stopwords:\n",
        "                temp.append(morph.lex)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlLC9trCBrX",
        "outputId": "271b8649-da27-4388-d999-5996fe93e5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(temp)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['너무', '재밌', '어요']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro25nY_pEphF"
      },
      "source": [
        "def predict(original_sentence):\n",
        "    sentence = ['CLS']\n",
        "    for word in api.analyze(original_sentence):\n",
        "        for morph in word.morphs:\n",
        "            if morph.lex not in stopwords:\n",
        "                    sentence.append(morph.lex)\n",
        "    sentence.append('SEP')\n",
        "    x = tokenizer.texts_to_sequences([sentence])\n",
        "    x = pad_sequences(x, maxlen = pad_len,padding='post') # 패딩\n",
        "    x = torch.tensor(x).to(device).long()\n",
        "    \n",
        "    y = model(x)\n",
        "    if(y > 0):\n",
        "        return 'P'\n",
        "    else:\n",
        "        return 'B'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUV5hodObq8",
        "outputId": "72e8604c-a613-44b7-85b7-68e18cc0bbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(predict(\" 씨발\"))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wO2Fq0c9BWB",
        "outputId": "1d6f58be-3b44-4070-da78-0456018c47ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install pymysql\n",
        "import pymysql"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymysql\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/ea/dd9c81e2d85efd03cfbf808736dd055bd9ea1a78aea9968888b1055c3263/PyMySQL-0.10.1-py2.py3-none-any.whl (47kB)\n",
            "\r\u001b[K     |██████▉                         | 10kB 28.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leup3fjAM9fz"
      },
      "source": [
        "conn = pymysql.connect(host='jukerdb.cwhsnjoqybdo.ap-northeast-2.rds.amazonaws.com', user='admin', password='',\n",
        "                       db='WEB', charset='utf8')\n",
        " \n",
        "try:\n",
        "    # Connection 으로부터 Cursor 생성\n",
        "    curs = conn.cursor()\n",
        "\n",
        "    sql = \"select * from reply where class = %s\"\n",
        "    curs.execute(sql,'N')\n",
        "    reply = curs.fetchall()\n",
        "    #print(reply)     # 전체 rows\n",
        "\n",
        "    sql = \"select * from rereply where class = %s\"\n",
        "    curs.execute(sql,'N')\n",
        "    reply2 = curs.fetchall()\n",
        "    #print(reply2)     # 전체 rows\n",
        "\n",
        "    update_temp = []\n",
        "    update_temp2 = []\n",
        "    for line in reply:\n",
        "        # 0 pageid / 1 reid / 5 content\n",
        "        update_temp.append((line[0],line[1],predict(line[5])))\n",
        "    for line in reply2:\n",
        "        # 0 pageid / 1 reid / 2 rereid / 5 content\n",
        "        update_temp2.append((line[0],line[1],line[2],predict(line[6])))\n",
        "\n",
        "    for update in update_temp:\n",
        "        sql = \"\"\"UPDATE reply SET class = %s WHERE pageid = %s AND reid = %s\"\"\"\n",
        "        val = (update[2],update[0],update[1])\n",
        "        curs.execute(sql,val)\n",
        "        conn.commit()\n",
        "\n",
        "    for update in update_temp2:\n",
        "        sql = \"\"\"UPDATE rereply SET class = %s WHERE pageid = %s AND reid = %s AND rereid = %s\"\"\"\n",
        "        val = (update[3],update[0],update[1],update[2])\n",
        "        curs.execute(sql,val)\n",
        "        conn.commit()\n",
        "\n",
        "finally:\n",
        "    # Connection 닫기\n",
        "    conn.close()"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}