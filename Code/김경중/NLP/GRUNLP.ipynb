{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRUNLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ5XqGp4hzBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "d21ed5c0-337f-4ee7-b651-d0387448fd2d"
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install torchtext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: tweepy, beautifulsoup4, colorama, JPype1, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EDE73Tj0qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from konlpy.tag import Okt\n",
        "#주요 참고 PyTorch로 시작하는 딥 러닝 입문, 유원준\n",
        "from torchtext import data  \n",
        "from konlpy.tag import Mecab\n",
        "import urllib.request\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PuVz4sR4qHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b2fafda-7c62-46d4-a15b-5f9231c00ffa"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RS5jL4SkhOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74470147-0091-4d35-fed9-5b8aaccced1e"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7f5c15830710>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvdtqYt5mmQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "07e0b707-b123-47a5-b02b-cd6a3c666784"
      },
      "source": [
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "train_df.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                           document  label\n",
              "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLX6F44fzW7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHg2xnprnTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Mecab()\n",
        "# 필드 정의\n",
        "ID = data.Field(sequential = False,\n",
        "                use_vocab = False) # 실제 사용은 하지 않을 예정\n",
        "\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  use_vocab=True,\n",
        "                  tokenize=tokenizer.morphs, # 토크나이저로는 Mecab 사용.\n",
        "                  lower=True,\n",
        "                  batch_first=True,\n",
        "                  fix_length=20)\n",
        "\n",
        "LABEL = data.Field(sequential=False,\n",
        "                   use_vocab=False,\n",
        "                   is_target=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIuFuZ7ir_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "        path='.', train='ratings_train.txt', test='ratings_test.txt', format='tsv',\n",
        "        fields=[('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKWmYgDuvR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fae65789-0b40-4a8f-9e4f-9b9dbfd9b0dc"
      },
      "source": [
        "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
        "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플의 개수 : 150000\n",
            "테스트 샘플의 개수 : 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHBBK93vUD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "097c3853-3bc5-4104-a40b-aaf30cf10800"
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=10, max_size=10000)\n",
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 10002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L63-GVYV9cr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class grumodel(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grumodel, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        self.gru2 = nn.GRU(self.hidden_dim*2, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim*4,self.hidden_dim*2)\n",
        "        self.mlp2 = nn.Linear(self.hidden_dim*2,self.hidden_dim)\n",
        "        self.mlp3 = nn.Linear(self.hidden_dim,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.sigmoid(x).squeeze()\n",
        "        return x\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjw7hAukyIA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function,train_iter,DEVICE):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGQ9n6OHyJmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_iter, loss_function, DEVICE):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        total_loss += loss.item()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    return avg_loss"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi95_Js3_JKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "'''\n",
        "train_iter, val_iter = data.BucketIterator.splits(\n",
        "        (train_data, test_data), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "'''\n",
        "from torchtext.data import Iterator\n",
        "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
        "val_loader = Iterator(dataset=test_data, batch_size = batch_size)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxInl4U70p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = grumodel(128,10002,256,1,100,0.3)\n",
        "model.to(device)\n",
        "loss = nn.BCELoss()\n",
        "lr = 0.001\n",
        "\n",
        "EPOCHS = 10\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZgooCDayPBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7e489836-6f27-4675-b73f-d323e84e884e"
      },
      "source": [
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, loss,train_loader,device)\n",
        "    val_loss = evaluate(model, val_loader, loss, device)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %1.5f \" % (e, val_loss))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        print(\"Best saved\")\n",
        "        torch.save(model.state_dict(), '/content/gdrive/My Drive/GRUmodel/NLP_esemble_model.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] val loss : 0.00440 \n",
            "Best saved\n",
            "[Epoch: 2] val loss : 0.00439 \n",
            "Best saved\n",
            "[Epoch: 3] val loss : 0.00458 \n",
            "[Epoch: 4] val loss : 0.00431 \n",
            "Best saved\n",
            "[Epoch: 5] val loss : 0.00427 \n",
            "Best saved\n",
            "[Epoch: 6] val loss : 0.00440 \n",
            "[Epoch: 7] val loss : 0.00439 \n",
            "[Epoch: 8] val loss : 0.00444 \n",
            "[Epoch: 9] val loss : 0.00498 \n",
            "[Epoch: 10] val loss : 0.00457 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33xBTcv5_GDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}