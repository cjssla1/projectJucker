{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRUNLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ5XqGp4hzBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "9c5138cc-82f8-4e8e-c83a-8fbfe0948551"
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install torchtext"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EDE73Tj0qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from konlpy.tag import Okt\n",
        "#주요 참고 PyTorch로 시작하는 딥 러닝 입문, 유원준\n",
        "from torchtext import data  \n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PuVz4sR4qHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27a15d9b-3acb-4dfa-f594-c4e7ac1ac4a4"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN_erJ23CSwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9dc0cb7-eac4-437d-91c5-28468bc3eabe"
      },
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f281f74e1f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLX6F44fzW7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "\n",
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "train_df.head(10)\n",
        "\n",
        "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "train_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_train.csv\", mode='w',index=False)\n",
        "test_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_test.csv\", mode='w',index=False)\n",
        "\n",
        "'''"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHg2xnprnTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Okt()\n",
        "# 필드 정의\n",
        "ID = data.Field(sequential = False,\n",
        "                use_vocab = False) \n",
        "\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  use_vocab=True,\n",
        "                  tokenize=tokenizer.morphs, \n",
        "                  lower=True,\n",
        "                  batch_first=True,\n",
        "                  fix_length=128)\n",
        "\n",
        "LABEL = data.Field(sequential=False,\n",
        "                   use_vocab=False,\n",
        "                   is_target=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIuFuZ7ir_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "train_data = TabularDataset(path='/content/gdrive/My Drive/datas/ratings_train.csv', format='csv',fields=[('id', ID), ('document', TEXT), ('label', LABEL)], skip_header=True)\n",
        "test_data = TabularDataset(path='/content/gdrive/My Drive/datas/ratings_test.csv', format='csv',fields=[('id', ID), ('document', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L63-GVYV9cr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class grumodel(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grumodel, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        self.gru2 = nn.GRU(self.hidden_dim*2, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim*4,self.hidden_dim)\n",
        "        self.mlp2 = nn.Linear(self.hidden_dim,self.hidden_dim//4)\n",
        "        self.mlp3 = nn.Linear(self.hidden_dim//4,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.sigmoid(x).squeeze()\n",
        "        return x\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWaetR63DxEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class grubase(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grubase, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim//2, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        #self.gru2 = nn.GRU(self.hidden_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim*2,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        x = self.sigmoid(x).squeeze()\n",
        "        return x\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjw7hAukyIA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function,train_iter,DEVICE):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb6iq80qMMOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getF1(y_pred,y,threshold=0.5):\n",
        "    \n",
        "    yp = [1 if x > threshold else 0 for x in y_pred]\n",
        "\n",
        "    pp = 0\n",
        "    pf = 0\n",
        "    fp = 0\n",
        "    ff = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] > threshold:\n",
        "            if yp[i] > threshold: pp += 1\n",
        "            else: pf += 1\n",
        "        else:\n",
        "            if yp[i] < threshold: ff += 1\n",
        "            else: fp += 1\n",
        "\n",
        "    precision = pp / (pp + fp + 1e-5) \n",
        "    recall = pp / (pp + ff + 1e-5)\n",
        "    F1 = 2 * precision * recall / (precision + recall + 1e-5)\n",
        "    acc = (pp + ff) / (len(y) + 1e-5)\n",
        "    return F1, acc"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGQ9n6OHyJmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_iter, loss_function, DEVICE, batch_size, threshold):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_f1 = 0\n",
        "    total_acc = 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        f1, acc = getF1(y_pred,y,threshold)\n",
        "        total_f1 += f1\n",
        "        total_acc += acc\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    size = len(val_iter.dataset) / batch_size\n",
        "    avg_loss = total_loss / size\n",
        "    avg_f1 = total_f1 / size\n",
        "    avg_acc = total_acc / size\n",
        "    return avg_loss, avg_f1, avg_acc"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKWmYgDuvR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0604cf8e-1433-4124-ab46-0421e9943d94"
      },
      "source": [
        "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
        "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플의 개수 : 143682\n",
            "테스트 샘플의 개수 : 49157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5PGWoeaboY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ba25f56-a913-4fdf-de4c-f02186b0f0da"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'id': '9976970', 'document': ['아', '더빙', '진짜', '짜증나네요', '목소리'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxInl4U70p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "vocab_size = 10000\n",
        "batch_size = 256\n",
        "embed_dim = 128\n",
        "hidden_dim = 256\n",
        "dropout = 0.6\n",
        "layers = 1\n",
        "\n",
        "model = grubase(embed_dim,vocab_size+2,hidden_dim,layers,batch_size,dropout)\n",
        "model.to(device)\n",
        "loss = nn.BCELoss()\n",
        "lr = 0.002\n",
        "threshold = 0.4\n",
        "\n",
        "EPOCHS = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHBBK93vUD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9835cff-0f2d-4a5f-9526-45f21c19b91f"
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=5, max_size=vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 10002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi95_Js3_JKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "train_iter, val_iter = data.BucketIterator.splits(\n",
        "        (train_data, test_data), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "'''\n",
        "from torchtext.data import Iterator\n",
        "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
        "val_loader = Iterator(dataset=test_data, batch_size = batch_size)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZgooCDayPBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "b27b1cb2-0ba9-4753-fcfe-338656a904e8"
      },
      "source": [
        "best_val_f1 = 0\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, loss,train_loader,device)\n",
        "    val_loss,val_f1,val_acc = evaluate(model, val_loader, loss, device,batch_size,threshold)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %1.5f    val acc :%4.3f    F1 :%4.3f\" % (e, val_loss, val_acc,val_f1))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_f1 or val_f1 > best_val_f1:\n",
        "        print(\"Best saved\")\n",
        "        torch.save(model.state_dict(), '/content/gdrive/My Drive/GRUmodel/NLP_esemble_model.pt')\n",
        "        best_val_f1 = val_f1"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] val loss : 0.43359    val acc :0.803    F1 :0.624\n",
            "Best saved\n",
            "[Epoch: 2] val loss : 0.38740    val acc :0.826    F1 :0.633\n",
            "Best saved\n",
            "[Epoch: 3] val loss : 0.38005    val acc :0.838    F1 :0.625\n",
            "[Epoch: 4] val loss : 0.36578    val acc :0.838    F1 :0.643\n",
            "Best saved\n",
            "[Epoch: 5] val loss : 0.36083    val acc :0.845    F1 :0.639\n",
            "[Epoch: 6] val loss : 0.35506    val acc :0.844    F1 :0.643\n",
            "[Epoch: 7] val loss : 0.35478    val acc :0.847    F1 :0.636\n",
            "[Epoch: 8] val loss : 0.35239    val acc :0.848    F1 :0.641\n",
            "[Epoch: 9] val loss : 0.35210    val acc :0.846    F1 :0.641\n",
            "[Epoch: 10] val loss : 0.34766    val acc :0.846    F1 :0.645\n",
            "Best saved\n",
            "[Epoch: 11] val loss : 0.35294    val acc :0.848    F1 :0.644\n",
            "[Epoch: 12] val loss : 0.34925    val acc :0.845    F1 :0.643\n",
            "[Epoch: 13] val loss : 0.35409    val acc :0.848    F1 :0.643\n",
            "[Epoch: 14] val loss : 0.35669    val acc :0.851    F1 :0.637\n",
            "[Epoch: 15] val loss : 0.34809    val acc :0.849    F1 :0.641\n",
            "[Epoch: 16] val loss : 0.35585    val acc :0.847    F1 :0.643\n",
            "[Epoch: 17] val loss : 0.35923    val acc :0.845    F1 :0.643\n",
            "[Epoch: 18] val loss : 0.35454    val acc :0.843    F1 :0.646\n",
            "Best saved\n",
            "[Epoch: 19] val loss : 0.35785    val acc :0.846    F1 :0.644\n",
            "[Epoch: 20] val loss : 0.36541    val acc :0.850    F1 :0.638\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}