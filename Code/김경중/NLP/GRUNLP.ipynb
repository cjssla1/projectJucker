{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRUNLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ5XqGp4hzBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "0dd0b767-6775-42a5-caf6-6220328076a7"
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install torchtext"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EDE73Tj0qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from konlpy.tag import Okt\n",
        "#주요 참고 PyTorch로 시작하는 딥 러닝 입문, 유원준\n",
        "from torchtext import data  \n",
        "from konlpy.tag import Mecab\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PuVz4sR4qHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ebc56e1-5662-4896-e8ba-48bd0192a94f"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN_erJ23CSwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04c39651-4845-47b0-fd08-0c106d05deb1"
      },
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcd6b8811f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RS5jL4SkhOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0ea8e198-eccb-410c-ba86-6613678144aa"
      },
      "source": [
        "'''\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "'''"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvdtqYt5mmQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71a5be79-de3f-4265-eb31-19b6b7ff4845"
      },
      "source": [
        "'''\n",
        "train_df = pd.read_table('ratings_train.txt')\n",
        "test_df = pd.read_table('ratings_test.txt')\n",
        "train_df.head(10)\n",
        "'''"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntrain_df = pd.read_table('ratings_train.txt')\\ntest_df = pd.read_table('ratings_test.txt')\\ntrain_df.head(10)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLX6F44fzW7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "636dbda6-03b8-4efb-a7fd-1c4c100c2358"
      },
      "source": [
        "'''\n",
        "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "train_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_train.csv\", mode='w',index=False)\n",
        "test_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_test.csv\", mode='w',index=False)\n",
        "'''"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntrain_df.drop_duplicates(subset=[\\'document\\'], inplace=True)\\ntest_df.drop_duplicates(subset=[\\'document\\'], inplace=True)\\ntrain_df.dropna(inplace=True)\\ntest_df.dropna(inplace=True)\\n\\ntrain_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_train.csv\", mode=\\'w\\',index=False)\\ntest_df.to_csv(\"/content/gdrive/My Drive/datas/ratings_test.csv\", mode=\\'w\\',index=False)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHg2xnprnTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Okt()\n",
        "# 필드 정의\n",
        "ID = data.Field(sequential = False,\n",
        "                use_vocab = False) \n",
        "\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  use_vocab=True,\n",
        "                  tokenize=tokenizer.morphs, \n",
        "                  lower=True,\n",
        "                  batch_first=True,\n",
        "                  fix_length=256)\n",
        "\n",
        "LABEL = data.Field(sequential=False,\n",
        "                   use_vocab=False,\n",
        "                   is_target=True)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIuFuZ7ir_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "train_data = TabularDataset(path='/content/gdrive/My Drive/datas/ratings_train.csv', format='csv',fields=[('id', ID), ('document', TEXT), ('label', LABEL)], skip_header=True)\n",
        "test_data = TabularDataset(path='/content/gdrive/My Drive/datas/ratings_test.csv', format='csv',fields=[('id', ID), ('document', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L63-GVYV9cr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class grumodel(nn.Module):\n",
        "    def __init__(self, embed_dim, vocab_size, hidden_dim, num_layers, batch_size, dropout):\n",
        "        super(grumodel, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_size = batch_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.norm = nn.BatchNorm1d(self.batch_size)\n",
        "        self.embed = nn.Embedding(self.vocab_size,self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.gru = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "        self.gru2 = nn.GRU(self.hidden_dim*2, self.hidden_dim, self.num_layers,bidirectional=True,batch_first=True)\n",
        "\n",
        "        self.mlp1 = nn.Linear(self.hidden_dim*4,self.hidden_dim)\n",
        "        self.mlp2 = nn.Linear(self.hidden_dim,self.hidden_dim//4)\n",
        "        self.mlp3 = nn.Linear(self.hidden_dim//4,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embed(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, _ = self.gru(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = torch.cat((x[:,0,:],x[:,-1,:]),dim=-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.mlp1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.sigmoid(x).squeeze()\n",
        "        return x\n"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjw7hAukyIA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function,train_iter,DEVICE):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb6iq80qMMOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getF1(y_pred,y,threshold=0.5):\n",
        "    \n",
        "    yp = [1 if x > threshold else 0 for x in y_pred]\n",
        "\n",
        "    pp = 0\n",
        "    pf = 0\n",
        "    fp = 0\n",
        "    ff = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] > threshold:\n",
        "            if yp[i] > threshold: pp += 1\n",
        "            else: pf += 1\n",
        "        else:\n",
        "            if yp[i] < threshold: ff += 1\n",
        "            else: fp += 1\n",
        "\n",
        "    precision = pp / (pp + fp + 1e-5) \n",
        "    recall = pp / (pp + ff + 1e-5)\n",
        "    F1 = 2 * precision * recall / (precision + recall + 1e-5)\n",
        "    acc = (pp + ff) / (len(y) + 1e-5)\n",
        "    return F1, acc"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGQ9n6OHyJmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_iter, loss_function, DEVICE, batch_size):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_f1 = 0\n",
        "    total_acc = 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_function(y_pred.to(DEVICE).float(), y.float())\n",
        "        f1, acc = getF1(y_pred,y)\n",
        "        total_f1 += f1\n",
        "        total_acc += acc\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    size = len(val_iter.dataset) / batch_size\n",
        "    avg_loss = total_loss / size\n",
        "    avg_f1 = total_f1 / size\n",
        "    avg_acc = total_acc / size\n",
        "    return avg_loss, avg_f1, avg_acc"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKWmYgDuvR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "251b87a3-660d-47a8-dd00-4a82a57b1df7"
      },
      "source": [
        "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
        "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플의 개수 : 146182\n",
            "테스트 샘플의 개수 : 49157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5PGWoeaboY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d90dd6c-d98f-41e8-f178-7779cc89793f"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'id': '9976970', 'document': ['아', '더빙', '..', '진짜', '짜증나네요', '목소리'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxInl4U70p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "vocab_size = 6000\n",
        "batch_size = 100\n",
        "embed_dim = 128\n",
        "hidden_dim = 256\n",
        "dropout = 0.6\n",
        "layers = 1\n",
        "\n",
        "model = grumodel(embed_dim,vocab_size+2,hidden_dim,layers,batch_size,dropout)\n",
        "model.to(device)\n",
        "loss = nn.BCELoss()\n",
        "lr = 0.002\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHBBK93vUD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "143397a0-80cc-4214-ff2c-0abc82ce1d4a"
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=10, max_size=vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 6002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi95_Js3_JKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "train_iter, val_iter = data.BucketIterator.splits(\n",
        "        (train_data, test_data), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "'''\n",
        "from torchtext.data import Iterator\n",
        "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
        "val_loader = Iterator(dataset=test_data, batch_size = batch_size)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZgooCDayPBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "9dad9d5c-1edb-4bd2-bbad-edda5ddef262"
      },
      "source": [
        "best_val_f1 = 0\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, loss,train_loader,device)\n",
        "    val_loss,val_f1,val_acc = evaluate(model, val_loader, loss, device,batch_size)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %1.5f    val acc :%4.3f    F1 :%4.3f\" % (e, val_loss, val_acc,val_f1))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_f1 or val_f1 > best_val_f1:\n",
        "        print(\"Best saved\")\n",
        "        torch.save(model.state_dict(), '/content/gdrive/My Drive/GRUmodel/NLP_esemble_model.pt')\n",
        "        best_val_f1 = val_f1"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] val loss : 0.38204    val acc :0.828    F1 :0.613\n",
            "Best saved\n",
            "[Epoch: 2] val loss : 0.35676    val acc :0.839    F1 :0.616\n",
            "Best saved\n",
            "[Epoch: 3] val loss : 0.34753    val acc :0.847    F1 :0.622\n",
            "Best saved\n",
            "[Epoch: 4] val loss : 0.33957    val acc :0.849    F1 :0.630\n",
            "Best saved\n",
            "[Epoch: 5] val loss : 0.33959    val acc :0.849    F1 :0.629\n",
            "[Epoch: 6] val loss : 0.34386    val acc :0.849    F1 :0.631\n",
            "Best saved\n",
            "[Epoch: 7] val loss : 0.33919    val acc :0.849    F1 :0.625\n",
            "[Epoch: 8] val loss : 0.34292    val acc :0.850    F1 :0.621\n",
            "[Epoch: 9] val loss : 0.34059    val acc :0.849    F1 :0.634\n",
            "Best saved\n",
            "[Epoch: 10] val loss : 0.34776    val acc :0.851    F1 :0.626\n",
            "[Epoch: 11] val loss : 0.34296    val acc :0.850    F1 :0.626\n",
            "[Epoch: 12] val loss : 0.33639    val acc :0.850    F1 :0.628\n",
            "[Epoch: 13] val loss : 0.35115    val acc :0.849    F1 :0.623\n",
            "[Epoch: 14] val loss : 0.34559    val acc :0.848    F1 :0.631\n",
            "[Epoch: 15] val loss : 0.33965    val acc :0.850    F1 :0.629\n",
            "[Epoch: 16] val loss : 0.36606    val acc :0.848    F1 :0.626\n",
            "[Epoch: 17] val loss : 0.35203    val acc :0.846    F1 :0.631\n",
            "[Epoch: 18] val loss : 0.35674    val acc :0.845    F1 :0.618\n",
            "[Epoch: 19] val loss : 0.35737    val acc :0.847    F1 :0.625\n",
            "[Epoch: 20] val loss : 0.35565    val acc :0.845    F1 :0.628\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}