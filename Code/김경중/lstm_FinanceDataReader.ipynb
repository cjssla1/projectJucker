{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_FinanceDataReader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBGcFiqYmQ8vm157Yjwngk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_PEUy181BAQ",
        "colab_type": "code",
        "outputId": "126c33b6-dc4d-4d51-c762-383623af48cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "!pip install -U finance-datareader\n",
        "!pip install torch torchvision"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: finance-datareader in /usr/local/lib/python3.6/dist-packages (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: requests-file in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from requests-file->finance-datareader) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJJ5ZfD1Pj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import FinanceDataReader as fdr\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "from copy import deepcopy # Add Deepcopy for args\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGuZSIOr1TJk",
        "colab_type": "code",
        "outputId": "05d9b14a-fa80-40ca-b5ea-e1b2c40ff5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''import FinanceDataReader as fdr\n",
        "\n",
        "# 한국거래소 상장종목 전체\n",
        "df_krx = fdr.StockListing('KRX')\n",
        "df_krx.head()'''"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import FinanceDataReader as fdr\\n\\n# 한국거래소 상장종목 전체\\ndf_krx = fdr.StockListing('KRX')\\ndf_krx.head()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5jm0Urv1gt_",
        "colab_type": "code",
        "outputId": "2ac16597-7714-42a3-a577-3e24646dc1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import FinanceDataReader as fdr\n",
        "\n",
        "df = fdr.DataReader('068270')\n",
        "df.tail(10)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-27</th>\n",
              "      <td>213500</td>\n",
              "      <td>215000</td>\n",
              "      <td>211500</td>\n",
              "      <td>212500</td>\n",
              "      <td>486289</td>\n",
              "      <td>0.004728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28</th>\n",
              "      <td>212500</td>\n",
              "      <td>214000</td>\n",
              "      <td>208000</td>\n",
              "      <td>209000</td>\n",
              "      <td>726697</td>\n",
              "      <td>-0.016471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-29</th>\n",
              "      <td>209000</td>\n",
              "      <td>211000</td>\n",
              "      <td>207000</td>\n",
              "      <td>210500</td>\n",
              "      <td>654481</td>\n",
              "      <td>0.007177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-04</th>\n",
              "      <td>208000</td>\n",
              "      <td>211000</td>\n",
              "      <td>203500</td>\n",
              "      <td>203500</td>\n",
              "      <td>860366</td>\n",
              "      <td>-0.033254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-06</th>\n",
              "      <td>204500</td>\n",
              "      <td>208000</td>\n",
              "      <td>200500</td>\n",
              "      <td>207000</td>\n",
              "      <td>603987</td>\n",
              "      <td>0.017199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-07</th>\n",
              "      <td>206000</td>\n",
              "      <td>207000</td>\n",
              "      <td>203500</td>\n",
              "      <td>204000</td>\n",
              "      <td>402708</td>\n",
              "      <td>-0.014493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>206000</td>\n",
              "      <td>214000</td>\n",
              "      <td>205000</td>\n",
              "      <td>210500</td>\n",
              "      <td>895729</td>\n",
              "      <td>0.031863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-11</th>\n",
              "      <td>215000</td>\n",
              "      <td>215500</td>\n",
              "      <td>210000</td>\n",
              "      <td>210500</td>\n",
              "      <td>695048</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12</th>\n",
              "      <td>212000</td>\n",
              "      <td>217500</td>\n",
              "      <td>210500</td>\n",
              "      <td>211000</td>\n",
              "      <td>982920</td>\n",
              "      <td>0.002375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-13</th>\n",
              "      <td>211000</td>\n",
              "      <td>215000</td>\n",
              "      <td>210000</td>\n",
              "      <td>215000</td>\n",
              "      <td>752857</td>\n",
              "      <td>0.018957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close  Volume    Change\n",
              "Date                                                        \n",
              "2020-04-27  213500  215000  211500  212500  486289  0.004728\n",
              "2020-04-28  212500  214000  208000  209000  726697 -0.016471\n",
              "2020-04-29  209000  211000  207000  210500  654481  0.007177\n",
              "2020-05-04  208000  211000  203500  203500  860366 -0.033254\n",
              "2020-05-06  204500  208000  200500  207000  603987  0.017199\n",
              "2020-05-07  206000  207000  203500  204000  402708 -0.014493\n",
              "2020-05-08  206000  214000  205000  210500  895729  0.031863\n",
              "2020-05-11  215000  215500  210000  210500  695048  0.000000\n",
              "2020-05-12  212000  217500  210500  211000  982920  0.002375\n",
              "2020-05-13  211000  215000  210000  215000  752857  0.018957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmVW-bIU2DiM",
        "colab_type": "code",
        "outputId": "9362daa5-9f0d-4732-905f-0e632c7289a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "df['Close'].plot()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d329d8898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwolCRaU_xPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StockDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, symbol, x_frames, y_frames, start, end):\n",
        "        \n",
        "        self.symbol = symbol\n",
        "        self.x_frames = x_frames\n",
        "        self.y_frames = y_frames\n",
        "        \n",
        "        self.start = datetime.datetime(*start)\n",
        "        self.end = datetime.datetime(*end)\n",
        "\n",
        "        self.data = fdr.DataReader(self.symbol, self.start, self.end)\n",
        "        print(self.data.isna().sum())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        idx += self.x_frames\n",
        "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
        "        data = data[['High', 'Low', 'Open', 'Close', 'Change', 'Volume']]\n",
        "        data = data.apply(lambda x: np.log(x+1) - np.log(x[self.x_frames-1]+1))\n",
        "        data = data.values\n",
        "        X = data[:self.x_frames]\n",
        "        y = data[self.x_frames:]\n",
        "        \n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrarBrskRsgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StockDataset2(Dataset):\n",
        "    \n",
        "    def __init__(self, symbol, x_frames, y_frames, start, end):\n",
        "        \n",
        "        self.symbol = symbol\n",
        "        self.x_frames = x_frames\n",
        "        self.y_frames = y_frames\n",
        "        \n",
        "        self.start = datetime.datetime(*start)\n",
        "        self.end = datetime.datetime(*end)\n",
        "\n",
        "        self.data = fdr.DataReader(self.symbol, self.start, self.end)\n",
        "        print(self.data.isna().sum())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx += self.x_frames\n",
        "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
        "        data = data[['High', 'Low', 'Open', 'Close', 'Change', 'Volume']]\n",
        "        \n",
        "        #data = data.apply(lambda x: np.log(x+1) - np.log(x[self.x_frames-1]+1))\n",
        "        data = data.values\n",
        "        X = data[:self.x_frames]\n",
        "        y = data[self.x_frames:]\n",
        "        \n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2tPnyn-_xXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, batch_size, dropout, use_bn):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_dim = input_dim \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout = dropout\n",
        "        self.use_bn = use_bn \n",
        "        \n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
        "        self.hidden = self.init_hidden()\n",
        "        self.regressor = self.make_regressor()\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "    \n",
        "    def make_regressor(self):\n",
        "        layers = []\n",
        "        if self.use_bn:\n",
        "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
        "        layers.append(nn.Dropout(self.dropout))\n",
        "        \n",
        "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
        "        regressor = nn.Sequential(*layers)\n",
        "        return regressor\n",
        "    \n",
        "    def forward(self, x):\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tRh2d2Z_xas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metric(y_pred, y_true):\n",
        "    perc_y_pred = np.exp(y_pred.cpu().detach().numpy())\n",
        "    perc_y_true = np.exp(y_true.cpu().detach().numpy())\n",
        "    mae = mean_absolute_error(perc_y_true, perc_y_pred, multioutput='raw_values')\n",
        "    return mae*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG6vVCAx_xdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, partition, optimizer, loss_fn, args):\n",
        "    trainloader = DataLoader(partition['train'], \n",
        "                             batch_size=args.batch_size, \n",
        "                             shuffle=True, drop_last=True)\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "\n",
        "        X = X.transpose(0, 1).float().to(args.device)\n",
        "        y_true = y[:, :, 3].float().to(args.device)\n",
        "        #print(torch.max(X[:, :, 3]), torch.max(y_true))\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = train_acc / len(trainloader)\n",
        "    return model, train_loss, train_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku7XiokK_xgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, partition, loss_fn, args):\n",
        "    valloader = DataLoader(partition['val'], \n",
        "                           batch_size=args.batch_size, \n",
        "                           shuffle=False, drop_last=True)\n",
        "    model.eval()\n",
        "\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(valloader):\n",
        "\n",
        "            X = X.transpose(0, 1).float().to(args.device)\n",
        "            y_true = y[:, :, 3].float().to(args.device)\n",
        "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "            y_pred = model(X)\n",
        "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    val_loss = val_loss / len(valloader)\n",
        "    val_acc = val_acc / len(valloader)\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsVSh2G6_xjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, partition, args):\n",
        "    testloader = DataLoader(partition['test'], \n",
        "                           batch_size=args.batch_size, \n",
        "                           shuffle=False, drop_last=True)\n",
        "    model.eval()\n",
        "\n",
        "    test_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(testloader):\n",
        "\n",
        "            X = X.transpose(0, 1).float().to(args.device)\n",
        "            y_true = y[:, :, 3].float().to(args.device)\n",
        "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "            y_pred = model(X)\n",
        "            test_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    test_acc = test_acc / len(testloader)\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nlZT8q9_75v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(partition, model, args):\n",
        "\n",
        "    model.to(args.device)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "    \n",
        "    # ===== List for epoch-wise data ====== #\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    # ===================================== #\n",
        "        \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        model, train_loss, train_acc = train(model, partition, optimizer, loss_fn, args)\n",
        "        val_loss, val_acc = validate(model, partition, loss_fn, args)\n",
        "        te = time.time()\n",
        "        \n",
        "        # ====== Add Epoch Data ====== #\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        # ============================ #\n",
        "        \n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "        \n",
        "    test_acc = test(model, partition, args)    \n",
        "    \n",
        "    # ======= Add Result to Dictionary ======= #\n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['train_accs'] = train_accs\n",
        "    result['val_accs'] = val_accs\n",
        "    result['train_acc'] = train_acc\n",
        "    result['val_acc'] = val_acc\n",
        "    result['test_acc'] = test_acc\n",
        "    return vars(args), result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKwKID0Bj4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 666\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ====== Data Loading ====== #\n",
        "args.symbol = '028050'\n",
        "args.batch_size = 128\n",
        "args.x_frames = 5\n",
        "args.y_frames = 5\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJuNUl8M_78m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "db580bad-f1b8-4d10-d858-b3b14626d051"
      },
      "source": [
        "trainset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2000,1,1), (2012,1,1))\n",
        "valset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2012,1,1), (2016,1,1))\n",
        "testset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2016,1,1), (2019,2,1))\n",
        "partition = {'train': trainset, 'val':valset, 'test':testset}"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GemVeSU3_7_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fa2c8104-54d4-494b-bbe0-5a247f1ad3e2"
      },
      "source": [
        "\n",
        "# ====== Model Capacity ===== #\n",
        "args.input_dim = 6\n",
        "args.hid_dim = 50\n",
        "args.n_layers = 2\n",
        "\n",
        "# ====== Regularization ======= #\n",
        "args.l2 = 0.00001\n",
        "args.dropout = 0.0\n",
        "args.use_bn = True\n",
        "\n",
        "# ====== Optimizer & Training ====== #\n",
        "args.optim = 'Adam' #'RMSprop' #SGD, RMSprop, ADAM...\n",
        "args.lr = 0.0001\n",
        "args.epoch = 2\n",
        "\n",
        "\n",
        "# ====== Experiment Variable ====== #\n",
        "name_var1 = 'lr'\n",
        "name_var2 = 'n_layers'\n",
        "var1 = 0.0001\n",
        "var2 = 2\n",
        "\n",
        "model = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
        "\n",
        "\n",
        "setattr(args, name_var1, var1)\n",
        "setattr(args, name_var2, var2)\n",
        "print(args)\n",
        "        \n",
        "setting, result = experiment(partition, model,deepcopy(args))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=128, device='cuda', dropout=0.0, epoch=2, hid_dim=50, input_dim=6, l2=1e-05, lr=0.0001, n_layers=2, optim='Adam', symbol='028050', use_bn=True, x_frames=5, y_frames=5)\n",
            "Epoch 0, Acc(train/val): 12.76/3.95, Loss(train/val) 0.02130/0.01029. Took 31.65 sec\n",
            "Epoch 1, Acc(train/val): 6.39/3.90, Loss(train/val) 0.01011/0.00969. Took 31.28 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhiQl07pOXdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "16355957-7eb6-418e-e3e8-797cb3cf7de1"
      },
      "source": [
        "k = fdr.DataReader('068270')\n",
        "k.tail(10)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-27</th>\n",
              "      <td>213500</td>\n",
              "      <td>215000</td>\n",
              "      <td>211500</td>\n",
              "      <td>212500</td>\n",
              "      <td>486289</td>\n",
              "      <td>0.004728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28</th>\n",
              "      <td>212500</td>\n",
              "      <td>214000</td>\n",
              "      <td>208000</td>\n",
              "      <td>209000</td>\n",
              "      <td>726697</td>\n",
              "      <td>-0.016471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-29</th>\n",
              "      <td>209000</td>\n",
              "      <td>211000</td>\n",
              "      <td>207000</td>\n",
              "      <td>210500</td>\n",
              "      <td>654481</td>\n",
              "      <td>0.007177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-04</th>\n",
              "      <td>208000</td>\n",
              "      <td>211000</td>\n",
              "      <td>203500</td>\n",
              "      <td>203500</td>\n",
              "      <td>860366</td>\n",
              "      <td>-0.033254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-06</th>\n",
              "      <td>204500</td>\n",
              "      <td>208000</td>\n",
              "      <td>200500</td>\n",
              "      <td>207000</td>\n",
              "      <td>603987</td>\n",
              "      <td>0.017199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-07</th>\n",
              "      <td>206000</td>\n",
              "      <td>207000</td>\n",
              "      <td>203500</td>\n",
              "      <td>204000</td>\n",
              "      <td>402708</td>\n",
              "      <td>-0.014493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>206000</td>\n",
              "      <td>214000</td>\n",
              "      <td>205000</td>\n",
              "      <td>210500</td>\n",
              "      <td>895729</td>\n",
              "      <td>0.031863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-11</th>\n",
              "      <td>215000</td>\n",
              "      <td>215500</td>\n",
              "      <td>210000</td>\n",
              "      <td>210500</td>\n",
              "      <td>695048</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12</th>\n",
              "      <td>212000</td>\n",
              "      <td>217500</td>\n",
              "      <td>210500</td>\n",
              "      <td>211000</td>\n",
              "      <td>982920</td>\n",
              "      <td>0.002375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-13</th>\n",
              "      <td>211000</td>\n",
              "      <td>215000</td>\n",
              "      <td>210000</td>\n",
              "      <td>215000</td>\n",
              "      <td>752857</td>\n",
              "      <td>0.018957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close  Volume    Change\n",
              "Date                                                        \n",
              "2020-04-27  213500  215000  211500  212500  486289  0.004728\n",
              "2020-04-28  212500  214000  208000  209000  726697 -0.016471\n",
              "2020-04-29  209000  211000  207000  210500  654481  0.007177\n",
              "2020-05-04  208000  211000  203500  203500  860366 -0.033254\n",
              "2020-05-06  204500  208000  200500  207000  603987  0.017199\n",
              "2020-05-07  206000  207000  203500  204000  402708 -0.014493\n",
              "2020-05-08  206000  214000  205000  210500  895729  0.031863\n",
              "2020-05-11  215000  215500  210000  210500  695048  0.000000\n",
              "2020-05-12  212000  217500  210500  211000  982920  0.002375\n",
              "2020-05-13  211000  215000  210000  215000  752857  0.018957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M_uHYH1HUKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "dee20f1d-6df9-46c7-b0ac-7ef111513930"
      },
      "source": [
        "testinput = StockDataset('068270',5,5,(2019,1,1),(2020,5,13))\n",
        "ts = StockDataset2('068270',5,5,(2019,1,1),(2020,5,13))\n",
        "testloader = DataLoader(testinput, batch_size=128, shuffle=False, drop_last=True)\n",
        "tt = DataLoader(testinput, batch_size=128, shuffle=False, drop_last=True)\n",
        "\n",
        "print(len(testloader))"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpklVy2L_8C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "result = []\n",
        "\n",
        "for i, (X,y) in enumerate(testloader):\n",
        "\n",
        "    model.eval()\n",
        "    X = X.transpose(0, 1).float().to(args.device)\n",
        "    y_true = y[:, :, 3].float().to(args.device)\n",
        "    model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "    y_pred = model(X)\n",
        "    y_pred = np.exp(y_pred.cpu().detach().numpy())\n",
        "    y_true = np.exp(y_true.cpu().detach().numpy())\n",
        "    result.append([y_pred,y_true,])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3zscG9_8Fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c6ddcd0-6423-4883-8b12-5975bcfcd8ac"
      },
      "source": [
        "\n",
        "print(result)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[217465.25, 177365.3 , 194624.72, 160632.77, 180967.1 ],\n",
            "       [221401.17, 175161.88, 190664.81, 161561.23, 173978.62],\n",
            "       [221747.12, 168730.97, 186857.48, 158990.92, 166639.23],\n",
            "       [223543.92, 184440.02, 194127.14, 158097.23, 182511.56],\n",
            "       [217196.75, 169792.02, 183331.22, 162933.42, 169211.02],\n",
            "       [208666.64, 160286.11, 185612.72, 160996.69, 168989.81],\n",
            "       [194990.48, 164391.72, 180853.28, 149783.5 , 171689.5 ],\n",
            "       [195046.36, 157889.05, 184601.9 , 144696.6 , 176515.6 ],\n",
            "       [194344.11, 160225.78, 186061.36, 149040.38, 180051.23],\n",
            "       [204404.9 , 164811.42, 189344.06, 158084.19, 186411.84],\n",
            "       [206874.9 , 174452.44, 194221.81, 164741.34, 186703.45],\n",
            "       [221663.81, 190457.73, 205612.48, 168840.72, 198428.94],\n",
            "       [216295.92, 182402.8 , 200406.02, 175500.62, 190855.61],\n",
            "       [218981.2 , 173509.17, 198964.81, 176935.61, 181084.  ],\n",
            "       [216969.19, 173749.12, 200806.34, 172494.45, 179775.89],\n",
            "       [237231.7 , 196595.78, 201852.38, 164509.12, 188811.19],\n",
            "       [232655.64, 187062.25, 203867.56, 175964.52, 185492.95],\n",
            "       [225081.08, 177439.3 , 198831.6 , 173228.27, 176979.5 ],\n",
            "       [224679.53, 179752.53, 203188.89, 172544.89, 179515.97],\n",
            "       [230163.5 , 199280.28, 223701.27, 162715.83, 194975.48],\n",
            "       [232364.72, 204770.23, 231148.19, 158580.11, 198906.42],\n",
            "       [221881.47, 198974.19, 240806.53, 157332.83, 213027.02],\n",
            "       [235458.58, 204813.12, 253216.4 , 162773.84, 219516.88],\n",
            "       [238655.3 , 206285.33, 262265.66, 167152.78, 215659.95],\n",
            "       [240917.47, 178109.31, 239469.31, 156079.84, 182716.31],\n",
            "       [242214.64, 186778.38, 232679.8 , 152430.02, 177078.45],\n",
            "       [244543.33, 187239.78, 237773.95, 150280.8 , 194506.75],\n",
            "       [244624.12, 198313.4 , 243026.33, 154099.08, 202919.36],\n",
            "       [222568.73, 184778.03, 246577.11, 151983.84, 208495.14],\n",
            "       [224459.11, 163272.16, 232100.61, 144160.7 , 188165.77],\n",
            "       [203985.66, 189363.47, 261916.77, 151045.36, 227926.58],\n",
            "       [225469.48, 173606.83, 219513.6 , 159860.77, 188065.61],\n",
            "       [213801.73, 173290.56, 213270.  , 170276.17, 180518.95],\n",
            "       [219638.14, 191191.38, 224278.1 , 161913.22, 191712.08],\n",
            "       [222698.7 , 179085.22, 211811.1 , 161150.8 , 175297.75],\n",
            "       [225649.52, 197556.34, 222025.66, 160126.23, 189145.95],\n",
            "       [226095.19, 183433.94, 215812.08, 164211.27, 178504.27],\n",
            "       [234040.28, 192337.67, 235901.08, 153461.17, 194539.44],\n",
            "       [225436.77, 202188.56, 239346.06, 152865.28, 201645.95],\n",
            "       [236733.5 , 208506.05, 256579.78, 159702.16, 203018.8 ],\n",
            "       [225226.62, 192955.  , 257972.5 , 154478.56, 209271.92],\n",
            "       [225627.33, 197961.86, 264121.44, 154583.17, 214227.5 ],\n",
            "       [194434.36, 183675.84, 259828.31, 162424.3 , 238652.39],\n",
            "       [187557.89, 168470.64, 231823.16, 143605.45, 206782.28],\n",
            "       [222628.17, 178470.39, 212750.98, 147441.92, 176743.47],\n",
            "       [230582.02, 194305.81, 232706.1 , 146938.23, 190068.3 ],\n",
            "       [209910.48, 186946.6 , 231756.25, 148214.42, 194507.95],\n",
            "       [213090.11, 199030.86, 228700.64, 147673.47, 185309.5 ],\n",
            "       [221503.89, 197257.27, 243939.73, 144632.02, 186813.28],\n",
            "       [192595.97, 174463.27, 256425.97, 141570.69, 206927.86],\n",
            "       [170560.44, 156466.55, 255656.03, 146245.98, 219932.58],\n",
            "       [159739.  , 168594.38, 185891.7 , 147158.45, 202699.56],\n",
            "       [147554.75, 162416.45, 166685.28, 160471.7 , 182753.72],\n",
            "       [171063.8 , 163942.83, 177382.98, 169939.12, 162559.98],\n",
            "       [191959.31, 161346.47, 188873.23, 163377.89, 157302.12],\n",
            "       [204899.64, 168681.22, 182649.1 , 145554.94, 176678.16],\n",
            "       [203998.64, 160404.02, 179728.61, 155053.19, 172892.38],\n",
            "       [213344.75, 176858.02, 187538.47, 158317.66, 179802.83],\n",
            "       [199651.52, 176324.88, 219717.78, 156328.75, 198364.34],\n",
            "       [201336.2 , 183482.69, 226115.61, 162419.53, 216924.9 ],\n",
            "       [207617.16, 202372.4 , 238452.3 , 161538.42, 216276.33],\n",
            "       [212488.3 , 203248.4 , 202390.7 , 163272.3 , 206028.92],\n",
            "       [219827.75, 165876.78, 215164.55, 160749.17, 175433.67],\n",
            "       [215731.52, 156427.  , 198375.48, 164453.22, 162307.88],\n",
            "       [207201.75, 180760.73, 209862.88, 156615.31, 199838.69],\n",
            "       [229879.27, 195559.42, 205876.03, 168484.05, 201316.17],\n",
            "       [229023.  , 199273.77, 246599.72, 164007.19, 213067.27],\n",
            "       [231783.08, 217505.67, 266868.4 , 171533.9 , 218876.02],\n",
            "       [243382.08, 219636.45, 272321.  , 166084.75, 216373.11],\n",
            "       [236898.6 , 201064.02, 218911.69, 165034.69, 195923.34],\n",
            "       [240758.67, 177752.19, 220203.5 , 170662.36, 176890.08],\n",
            "       [243071.28, 192112.64, 220446.34, 171728.92, 181963.53],\n",
            "       [229806.92, 205419.23, 236254.75, 159839.8 , 196529.6 ],\n",
            "       [239868.95, 213610.88, 221290.69, 158955.39, 187688.95],\n",
            "       [239102.28, 212521.83, 240283.97, 150431.33, 197036.16],\n",
            "       [236789.55, 197402.06, 229980.61, 160925.72, 213193.25],\n",
            "       [201015.53, 185920.86, 247649.55, 170025.92, 242777.53],\n",
            "       [194046.94, 191433.28, 259635.83, 169833.1 , 231421.78],\n",
            "       [193517.83, 194284.12, 268142.  , 154843.  , 225761.81],\n",
            "       [219603.05, 205191.31, 249407.12, 144164.34, 206318.61],\n",
            "       [234917.77, 202362.  , 250087.2 , 152012.05, 203153.42],\n",
            "       [228052.  , 168771.97, 222145.14, 146740.98, 177295.06],\n",
            "       [208237.33, 150122.48, 203903.56, 148527.52, 160753.78],\n",
            "       [214877.98, 171812.45, 199844.1 , 148502.92, 160207.88],\n",
            "       [225172.72, 189129.67, 193754.86, 142732.92, 162052.02],\n",
            "       [214177.83, 191743.28, 200669.17, 138516.67, 174925.77],\n",
            "       [209316.1 , 187021.66, 203115.44, 143137.6 , 174191.22],\n",
            "       [196837.81, 177468.94, 205413.84, 143167.11, 190004.19],\n",
            "       [216494.14, 184159.94, 204327.67, 140712.5 , 166784.84],\n",
            "       [192554.33, 158490.5 , 175173.94, 137309.81, 163342.1 ],\n",
            "       [187226.67, 153413.2 , 179461.39, 152708.  , 151933.47],\n",
            "       [190264.19, 145123.69, 177523.81, 150171.61, 156818.88],\n",
            "       [184389.56, 169501.1 , 181483.92, 151029.73, 173133.75],\n",
            "       [192994.02, 159363.42, 176373.64, 155193.2 , 167516.12],\n",
            "       [186142.81, 159874.97, 179269.22, 146577.6 , 172206.89],\n",
            "       [189668.64, 155566.28, 177174.22, 151856.42, 167322.2 ],\n",
            "       [200049.27, 173192.83, 194818.95, 154585.9 , 178770.98],\n",
            "       [201584.02, 165500.14, 184587.6 , 158036.14, 171021.3 ],\n",
            "       [216195.44, 182441.34, 188048.33, 155135.12, 179551.84],\n",
            "       [213144.98, 190233.88, 215650.77, 153668.27, 192367.89],\n",
            "       [216339.92, 196054.77, 227347.3 , 159204.25, 203960.61],\n",
            "       [201598.  , 191731.31, 223027.45, 167779.88, 211464.02],\n",
            "       [196810.22, 202393.67, 268631.88, 165316.84, 238347.66],\n",
            "       [194329.16, 198190.23, 265432.34, 159540.17, 243119.72],\n",
            "       [194275.86, 193381.5 , 281336.84, 162475.58, 253866.61],\n",
            "       [202517.25, 191477.75, 237231.55, 163085.  , 212707.9 ],\n",
            "       [230675.1 , 205398.5 , 254575.  , 158971.36, 211711.42],\n",
            "       [239827.47, 213035.12, 270227.6 , 166565.66, 209370.64],\n",
            "       [236507.52, 214016.36, 261054.06, 158678.92, 212717.66],\n",
            "       [246607.38, 213248.81, 256998.16, 161200.7 , 210115.42],\n",
            "       [235987.5 , 204930.47, 259103.77, 166572.94, 210750.38],\n",
            "       [228855.75, 188715.78, 231727.45, 160499.4 , 191494.52],\n",
            "       [232576.  , 200622.33, 245511.83, 162629.02, 205502.6 ],\n",
            "       [234337.52, 198279.47, 244629.53, 158680.72, 208212.45],\n",
            "       [200549.28, 198278.16, 263422.72, 161256.55, 233552.66],\n",
            "       [231534.95, 185442.23, 238568.44, 154421.27, 186192.42],\n",
            "       [207519.86, 180589.44, 267528.94, 149016.52, 226098.69],\n",
            "       [224188.11, 191593.6 , 250920.56, 153723.86, 212918.48],\n",
            "       [195194.02, 181995.58, 257432.11, 161635.34, 223536.92],\n",
            "       [190129.27, 183459.94, 254198.47, 159860.14, 220481.14],\n",
            "       [184546.45, 177650.98, 281721.3 , 149660.4 , 233309.48],\n",
            "       [181190.9 , 162590.45, 265463.28, 157501.23, 226343.75],\n",
            "       [172782.75, 176767.1 , 273461.62, 146520.14, 228210.84],\n",
            "       [160848.3 , 177338.78, 198207.16, 141419.22, 204979.36],\n",
            "       [172177.05, 153331.97, 195141.11, 143868.62, 168491.78],\n",
            "       [197943.56, 147988.03, 185609.88, 151293.56, 147057.94],\n",
            "       [195790.28, 171655.67, 193895.8 , 137665.05, 172728.33],\n",
            "       [197525.06, 156025.47, 173089.52, 146847.39, 157882.8 ]],\n",
            "      dtype=float32), tensor([[204401., 206789., 206789., 201536., 198193.],\n",
            "        [206789., 206789., 201536., 198193., 192939.],\n",
            "        [206789., 201536., 198193., 192939., 186731.],\n",
            "        [201536., 198193., 192939., 186731., 191984.],\n",
            "        [198193., 192939., 186731., 191984., 189119.],\n",
            "        [192939., 186731., 191984., 189119., 191029.],\n",
            "        [186731., 191984., 189119., 191029., 191029.],\n",
            "        [191984., 189119., 191029., 191029., 198670.],\n",
            "        [189119., 191029., 191029., 198670., 199148.],\n",
            "        [191029., 191029., 198670., 199148., 201536.],\n",
            "        [191029., 198670., 199148., 201536., 201058.],\n",
            "        [198670., 199148., 201536., 201058., 205356.],\n",
            "        [199148., 201536., 201058., 205356., 209177.],\n",
            "        [201536., 201058., 205356., 209177., 204879.],\n",
            "        [201058., 205356., 209177., 204879., 204401.],\n",
            "        [205356., 209177., 204879., 204401., 205356.],\n",
            "        [209177., 204879., 204401., 205356., 205834.],\n",
            "        [204879., 204401., 205356., 205834., 202968.],\n",
            "        [204401., 205356., 205834., 202968., 202491.],\n",
            "        [205356., 205834., 202968., 202491., 200580.],\n",
            "        [205834., 202968., 202491., 200580., 200103.],\n",
            "        [202968., 202491., 200580., 200103., 202491.],\n",
            "        [202491., 200580., 200103., 202491., 205356.],\n",
            "        [200580., 200103., 202491., 205356., 203923.],\n",
            "        [200103., 202491., 205356., 203923., 198193.],\n",
            "        [202491., 205356., 203923., 198193., 197715.],\n",
            "        [205356., 203923., 198193., 197715., 194850.],\n",
            "        [203923., 198193., 197715., 194850., 195327.],\n",
            "        [198193., 197715., 194850., 195327., 193417.],\n",
            "        [197715., 194850., 195327., 193417., 195327.],\n",
            "        [194850., 195327., 193417., 195327., 198193.],\n",
            "        [195327., 193417., 195327., 198193., 200580.],\n",
            "        [193417., 195327., 198193., 200580., 201536.],\n",
            "        [195327., 198193., 200580., 201536., 197715.],\n",
            "        [198193., 200580., 201536., 197715., 196760.],\n",
            "        [200580., 201536., 197715., 196760., 195805.],\n",
            "        [201536., 197715., 196760., 195805., 199625.],\n",
            "        [197715., 196760., 195805., 199625., 198193.],\n",
            "        [196760., 195805., 199625., 198193., 196760.],\n",
            "        [195805., 199625., 198193., 196760., 193894.],\n",
            "        [199625., 198193., 196760., 193894., 191984.],\n",
            "        [198193., 196760., 193894., 191984., 193894.],\n",
            "        [196760., 193894., 191984., 193894., 191984.],\n",
            "        [193894., 191984., 193894., 191984., 191507.],\n",
            "        [191984., 193894., 191984., 191507., 190551.],\n",
            "        [193894., 191984., 191507., 190551., 189119.],\n",
            "        [191984., 191507., 190551., 189119., 183865.],\n",
            "        [191507., 190551., 189119., 183865., 174792.],\n",
            "        [190551., 189119., 183865., 174792., 172404.],\n",
            "        [189119., 183865., 174792., 172404., 172881.],\n",
            "        [183865., 174792., 172404., 172881., 173836.],\n",
            "        [174792., 172404., 172881., 173836., 181478.],\n",
            "        [172404., 172881., 173836., 181478., 184821.],\n",
            "        [172881., 173836., 181478., 184821., 183865.],\n",
            "        [173836., 181478., 184821., 183865., 183388.],\n",
            "        [181478., 184821., 183865., 183388., 186731.],\n",
            "        [184821., 183865., 183388., 186731., 195327.],\n",
            "        [183865., 183388., 186731., 195327., 196282.],\n",
            "        [183388., 186731., 195327., 196282., 201058.],\n",
            "        [186731., 195327., 196282., 201058., 199625.],\n",
            "        [195327., 196282., 201058., 199625., 194372.],\n",
            "        [196282., 201058., 199625., 194372., 198670.],\n",
            "        [201058., 199625., 194372., 198670., 199148.],\n",
            "        [199625., 194372., 198670., 199148., 194372.],\n",
            "        [194372., 198670., 199148., 194372., 208222.],\n",
            "        [198670., 199148., 194372., 208222., 210610.],\n",
            "        [199148., 194372., 208222., 210610., 211565.],\n",
            "        [194372., 208222., 210610., 211565., 208222.],\n",
            "        [208222., 210610., 211565., 208222., 202013.],\n",
            "        [210610., 211565., 208222., 202013., 202491.],\n",
            "        [211565., 208222., 202013., 202491., 206311.],\n",
            "        [208222., 202013., 202491., 206311., 202491.],\n",
            "        [202013., 202491., 206311., 202491., 197715.],\n",
            "        [202491., 206311., 202491., 197715., 195327.],\n",
            "        [206311., 202491., 197715., 195327., 196282.],\n",
            "        [202491., 197715., 195327., 196282., 196282.],\n",
            "        [197715., 195327., 196282., 196282., 200580.],\n",
            "        [195327., 196282., 196282., 200580., 192462.],\n",
            "        [196282., 196282., 200580., 192462., 185776.],\n",
            "        [196282., 200580., 192462., 185776., 186731.],\n",
            "        [200580., 192462., 185776., 186731., 187208.],\n",
            "        [192462., 185776., 186731., 187208., 187686.],\n",
            "        [185776., 186731., 187208., 187686., 186731.],\n",
            "        [186731., 187208., 187686., 186731., 179567.],\n",
            "        [187208., 187686., 186731., 179567., 172881.],\n",
            "        [187686., 186731., 179567., 172881., 176224.],\n",
            "        [186731., 179567., 172881., 176224., 172404.],\n",
            "        [179567., 172881., 176224., 172404., 172881.],\n",
            "        [172881., 176224., 172404., 172881., 166195.],\n",
            "        [176224., 172404., 172881., 166195., 177657.],\n",
            "        [172404., 172881., 166195., 177657., 177179.],\n",
            "        [172881., 166195., 177657., 177179., 177657.],\n",
            "        [166195., 177657., 177179., 177657., 181478.],\n",
            "        [177657., 177179., 177657., 181478., 184343.],\n",
            "        [177179., 177657., 181478., 184343., 186731.],\n",
            "        [177657., 181478., 184343., 186731., 187208.],\n",
            "        [181478., 184343., 186731., 187208., 187686.],\n",
            "        [184343., 186731., 187208., 187686., 189596.],\n",
            "        [186731., 187208., 187686., 189596., 192939.],\n",
            "        [187208., 187686., 189596., 192939., 194850.],\n",
            "        [187686., 189596., 192939., 194850., 197715.],\n",
            "        [189596., 192939., 194850., 197715., 191984.],\n",
            "        [192939., 194850., 197715., 191984., 195805.],\n",
            "        [194850., 197715., 191984., 195805., 198670.],\n",
            "        [197715., 191984., 195805., 198670., 202013.],\n",
            "        [191984., 195805., 198670., 202013., 204401.],\n",
            "        [195805., 198670., 202013., 204401., 202968.],\n",
            "        [198670., 202013., 204401., 202968., 199148.],\n",
            "        [202013., 204401., 202968., 199148., 198670.],\n",
            "        [204401., 202968., 199148., 198670., 201058.],\n",
            "        [202968., 199148., 198670., 201058., 194850.],\n",
            "        [199148., 198670., 201058., 194850., 196282.],\n",
            "        [198670., 201058., 194850., 196282., 198670.],\n",
            "        [201058., 194850., 196282., 198670., 195805.],\n",
            "        [194850., 196282., 198670., 195805., 196760.],\n",
            "        [196282., 198670., 195805., 196760., 194372.],\n",
            "        [198670., 195805., 196760., 194372., 198670.],\n",
            "        [195805., 196760., 194372., 198670., 196760.],\n",
            "        [196760., 194372., 198670., 196760., 183865.],\n",
            "        [194372., 198670., 196760., 183865., 180522.],\n",
            "        [198670., 196760., 183865., 180522., 182910.],\n",
            "        [196760., 183865., 180522., 182910., 180045.],\n",
            "        [183865., 180522., 182910., 180045., 175269.],\n",
            "        [180522., 182910., 180045., 175269., 180045.],\n",
            "        [182910., 180045., 175269., 180045., 176224.],\n",
            "        [180045., 175269., 180045., 176224., 172404.],\n",
            "        [175269., 180045., 176224., 172404., 176224.],\n",
            "        [180045., 176224., 172404., 176224., 176224.]], device='cuda:0')], [array([[193099.52 , 152394.28 , 178903.2  , 150292.38 , 154244.31 ],\n",
            "       [203261.48 , 172452.38 , 177181.   , 141995.64 , 158091.66 ],\n",
            "       [195607.44 , 157194.28 , 172839.5  , 143966.22 , 148168.23 ],\n",
            "       [206602.95 , 171360.81 , 172082.56 , 137770.31 , 161298.44 ],\n",
            "       [188871.84 , 164974.1  , 191307.9  , 140132.31 , 168956.48 ],\n",
            "       [195141.45 , 176622.39 , 207544.   , 134500.2  , 177099.86 ],\n",
            "       [217398.27 , 176719.9  , 205657.98 , 131077.92 , 157455.8  ],\n",
            "       [206123.4  , 152478.5  , 191505.25 , 133377.94 , 141716.62 ],\n",
            "       [188150.6  , 142472.9  , 167549.36 , 134896.77 , 131315.27 ],\n",
            "       [196560.27 , 157725.84 , 167025.97 , 126383.44 , 127199.88 ],\n",
            "       [195019.75 , 167467.45 , 160195.75 , 111062.25 , 129353.71 ],\n",
            "       [177184.88 , 149438.48 , 137830.98 , 113316.09 , 130965.375],\n",
            "       [168669.67 , 124832.35 , 136830.3  , 118960.836, 132334.98 ],\n",
            "       [143113.8  , 120898.04 , 138043.89 , 114696.74 , 133043.4  ],\n",
            "       [141441.38 , 115852.68 , 134527.16 , 111061.555, 132480.44 ],\n",
            "       [140805.84 , 114964.375, 133994.98 , 106827.89 , 130506.48 ],\n",
            "       [146569.47 , 119831.13 , 141435.44 , 105728.78 , 132271.45 ],\n",
            "       [149898.95 , 121400.445, 141915.   , 106963.875, 133807.83 ],\n",
            "       [149541.12 , 122713.88 , 144295.19 , 108557.04 , 134403.73 ],\n",
            "       [155193.75 , 125571.766, 139694.38 , 114349.34 , 136602.98 ],\n",
            "       [165887.4  , 140398.6  , 143221.27 , 115858.336, 141300.48 ],\n",
            "       [161759.48 , 129642.47 , 144628.69 , 123240.13 , 128914.836],\n",
            "       [170318.72 , 144599.88 , 149587.47 , 117529.9  , 132592.83 ],\n",
            "       [168513.   , 151116.81 , 153794.77 , 123490.28 , 130113.97 ],\n",
            "       [167590.97 , 149368.72 , 164536.2  , 111191.96 , 138182.08 ],\n",
            "       [162590.23 , 134165.8  , 143948.11 , 116764.49 , 132714.6  ],\n",
            "       [161297.73 , 114664.2  , 140245.08 , 124075.83 , 128202.164],\n",
            "       [145961.67 , 114212.9  , 151577.19 , 124593.766, 126170.73 ],\n",
            "       [144635.44 , 127267.86 , 143449.25 , 116903.26 , 133496.95 ],\n",
            "       [153458.89 , 129709.875, 144960.7  , 114432.85 , 140134.52 ],\n",
            "       [153259.98 , 128128.484, 146213.8  , 115872.83 , 145723.95 ],\n",
            "       [153204.39 , 126741.85 , 151113.11 , 119665.91 , 142966.73 ],\n",
            "       [159805.78 , 131540.66 , 152175.97 , 122845.016, 145594.88 ],\n",
            "       [173780.27 , 152189.3  , 153207.4  , 123493.164, 150284.56 ],\n",
            "       [172304.89 , 145460.05 , 156891.06 , 124468.03 , 147627.06 ],\n",
            "       [161562.47 , 140742.5  , 157561.16 , 123057.79 , 147794.16 ],\n",
            "       [167386.81 , 137626.98 , 150747.9  , 130052.44 , 147081.22 ],\n",
            "       [175951.39 , 152014.64 , 175641.28 , 128339.42 , 160681.42 ],\n",
            "       [176220.62 , 163439.12 , 182610.22 , 129435.41 , 167799.95 ],\n",
            "       [182759.22 , 170942.33 , 195097.11 , 129023.86 , 167651.92 ],\n",
            "       [183740.55 , 152037.69 , 173373.8  , 126260.26 , 161176.19 ],\n",
            "       [180308.69 , 133818.38 , 170724.6  , 131395.06 , 140195.6  ],\n",
            "       [177529.47 , 130607.02 , 165957.94 , 133273.39 , 136170.92 ],\n",
            "       [174273.81 , 138947.19 , 155971.67 , 131942.02 , 138961.02 ],\n",
            "       [180667.11 , 135087.52 , 151042.77 , 131664.45 , 139922.69 ],\n",
            "       [177230.83 , 131814.02 , 148598.61 , 131371.34 , 137390.39 ],\n",
            "       [168914.17 , 135316.52 , 149597.39 , 123961.98 , 142102.7  ],\n",
            "       [162919.72 , 136080.6  , 153340.34 , 120061.695, 150651.19 ],\n",
            "       [169834.22 , 135877.   , 147457.9  , 132033.4  , 150110.44 ],\n",
            "       [180128.22 , 149449.73 , 161941.73 , 129601.49 , 154817.72 ],\n",
            "       [180962.47 , 165991.98 , 186234.75 , 133226.52 , 170921.08 ],\n",
            "       [184257.97 , 150408.36 , 173635.47 , 142516.05 , 154344.16 ],\n",
            "       [174596.38 , 140899.88 , 169798.31 , 135340.02 , 152158.4  ],\n",
            "       [174485.47 , 137019.83 , 168937.31 , 138979.97 , 145596.8  ],\n",
            "       [195877.2  , 162397.02 , 173782.48 , 137047.73 , 164376.4  ],\n",
            "       [188868.83 , 154219.61 , 168871.14 , 146356.05 , 156420.75 ],\n",
            "       [188155.22 , 148233.55 , 167541.66 , 146610.12 , 155646.66 ],\n",
            "       [188908.67 , 144822.81 , 166785.36 , 148011.34 , 154115.06 ],\n",
            "       [202520.94 , 163908.11 , 175507.6  , 143388.58 , 156220.56 ],\n",
            "       [198633.45 , 178379.98 , 195582.44 , 139163.08 , 172036.17 ],\n",
            "       [188850.67 , 174534.48 , 203574.72 , 142179.17 , 186880.06 ],\n",
            "       [218688.75 , 178924.62 , 202273.25 , 144366.31 , 183881.02 ],\n",
            "       [209926.1  , 180185.69 , 227643.23 , 148762.34 , 192428.52 ],\n",
            "       [223534.8  , 181472.45 , 234047.28 , 146043.7  , 178353.58 ],\n",
            "       [224586.89 , 192174.97 , 239976.05 , 144916.   , 193909.31 ],\n",
            "       [209162.1  , 168373.64 , 198048.62 , 150495.97 , 180278.25 ],\n",
            "       [197748.86 , 152423.47 , 189565.92 , 151998.52 , 168991.78 ],\n",
            "       [197070.95 , 157946.39 , 193258.06 , 155779.23 , 164307.16 ],\n",
            "       [218153.31 , 187561.44 , 194671.05 , 151339.5  , 179667.98 ],\n",
            "       [221885.19 , 195632.16 , 208938.66 , 149915.81 , 190007.17 ],\n",
            "       [214673.9  , 175898.27 , 195518.22 , 160554.92 , 169194.92 ],\n",
            "       [215263.58 , 188920.36 , 214488.34 , 155377.6  , 181452.55 ],\n",
            "       [226717.56 , 193327.12 , 217350.67 , 151971.48 , 170457.69 ],\n",
            "       [233027.17 , 192280.19 , 219867.4  , 147628.25 , 164986.72 ],\n",
            "       [228854.44 , 197766.1  , 199531.94 , 146539.55 , 166812.75 ],\n",
            "       [222826.42 , 188570.64 , 214831.02 , 145407.88 , 168642.27 ],\n",
            "       [208549.5  , 189880.38 , 214611.31 , 139486.23 , 174338.27 ],\n",
            "       [201763.45 , 164186.05 , 186337.28 , 136545.77 , 167696.03 ],\n",
            "       [194668.2  , 144219.89 , 180356.94 , 142344.16 , 153815.42 ],\n",
            "       [189757.73 , 138948.4  , 174252.19 , 143812.84 , 150324.22 ],\n",
            "       [190804.69 , 166101.84 , 186023.06 , 148265.73 , 165322.97 ],\n",
            "       [210097.83 , 179728.69 , 180609.92 , 143709.17 , 168286.23 ],\n",
            "       [197042.3  , 162694.28 , 174615.94 , 151185.5  , 149791.58 ],\n",
            "       [201157.5  , 173618.08 , 197948.98 , 138135.95 , 161993.08 ],\n",
            "       [203590.   , 183212.56 , 209751.73 , 134613.86 , 177940.62 ],\n",
            "       [199721.03 , 179441.17 , 203677.06 , 138840.34 , 179010.67 ],\n",
            "       [200796.47 , 171991.66 , 212271.23 , 145119.55 , 175194.11 ],\n",
            "       [183040.53 , 164724.77 , 179705.72 , 147681.25 , 162733.36 ],\n",
            "       [190806.95 , 140710.39 , 187652.05 , 140043.27 , 141845.81 ],\n",
            "       [194506.6  , 162299.03 , 179283.33 , 130771.   , 150719.19 ],\n",
            "       [194036.64 , 151274.11 , 164061.23 , 138845.3  , 147015.78 ],\n",
            "       [186020.84 , 141497.   , 161176.62 , 138605.53 , 140841.77 ],\n",
            "       [192798.44 , 160240.61 , 164432.69 , 132227.64 , 145224.62 ],\n",
            "       [184950.62 , 147954.05 , 160608.22 , 135552.56 , 140307.89 ],\n",
            "       [186942.92 , 159137.72 , 173394.64 , 133648.72 , 156010.22 ],\n",
            "       [187796.94 , 164109.33 , 189488.45 , 133935.28 , 158830.88 ],\n",
            "       [195741.19 , 167058.53 , 193464.1  , 124728.805, 151429.2  ],\n",
            "       [188049.17 , 139770.2  , 169456.75 , 128215.86 , 141187.02 ],\n",
            "       [195247.89 , 153870.27 , 192158.89 , 127357.09 , 160294.52 ],\n",
            "       [191347.4  , 157134.4  , 201669.14 , 126067.445, 165376.98 ],\n",
            "       [187507.17 , 142305.34 , 178609.72 , 128036.695, 153247.88 ],\n",
            "       [183045.45 , 144213.42 , 172765.53 , 143158.23 , 147139.9  ],\n",
            "       [170777.67 , 134580.48 , 167201.44 , 132715.78 , 149611.19 ],\n",
            "       [172263.2  , 145093.66 , 162925.6  , 139442.25 , 153219.22 ],\n",
            "       [189664.52 , 163197.72 , 182315.14 , 140200.84 , 174867.75 ],\n",
            "       [183204.5  , 162015.42 , 180392.14 , 138893.78 , 167682.1  ],\n",
            "       [185500.39 , 153626.95 , 176156.03 , 144443.3  , 163340.56 ],\n",
            "       [188491.94 , 150844.05 , 170913.27 , 148795.42 , 161489.16 ],\n",
            "       [193209.14 , 145451.78 , 172641.78 , 149948.31 , 156463.5  ],\n",
            "       [190715.1  , 149277.52 , 172791.3  , 149518.75 , 156955.61 ],\n",
            "       [196498.45 , 150510.72 , 169173.77 , 148163.72 , 153349.39 ],\n",
            "       [191144.52 , 146005.81 , 158651.77 , 133534.12 , 154225.84 ],\n",
            "       [184568.95 , 148082.67 , 165448.88 , 128916.85 , 159705.33 ],\n",
            "       [203318.08 , 169722.67 , 167394.77 , 136392.64 , 166410.61 ],\n",
            "       [194983.92 , 154582.25 , 172444.36 , 140420.33 , 159957.86 ],\n",
            "       [199660.84 , 173903.19 , 173563.61 , 141143.53 , 165526.44 ],\n",
            "       [196246.72 , 155642.34 , 175287.81 , 149555.58 , 156200.02 ],\n",
            "       [201636.77 , 174574.94 , 180069.36 , 146664.84 , 161945.52 ],\n",
            "       [190935.44 , 168199.31 , 178092.3  , 144048.73 , 163364.9  ],\n",
            "       [203139.53 , 181903.34 , 181476.67 , 142050.77 , 171132.73 ],\n",
            "       [204002.95 , 180592.42 , 192025.11 , 151160.5  , 170084.27 ],\n",
            "       [215251.25 , 180933.47 , 208052.95 , 137025.11 , 165448.55 ],\n",
            "       [210724.73 , 187975.7  , 192679.8  , 140073.11 , 163975.66 ],\n",
            "       [216812.8  , 183760.67 , 222352.3  , 137834.23 , 176943.1  ],\n",
            "       [193725.5  , 154181.4  , 182123.16 , 138686.75 , 161477.7  ],\n",
            "       [185430.66 , 149343.97 , 182262.66 , 144588.   , 148190.6  ],\n",
            "       [186835.81 , 151642.17 , 173062.   , 141828.   , 151180.06 ],\n",
            "       [196464.66 , 163377.98 , 178918.83 , 142094.84 , 158636.05 ]],\n",
            "      dtype=float32), tensor([[176224., 172404., 176224., 176224., 173836.],\n",
            "        [172404., 176224., 176224., 173836., 171926.],\n",
            "        [176224., 176224., 173836., 171926., 170016.],\n",
            "        [176224., 173836., 171926., 170016., 176702.],\n",
            "        [173836., 171926., 170016., 176702., 170971.],\n",
            "        [171926., 170016., 176702., 170971., 169061.],\n",
            "        [170016., 176702., 170971., 169061., 162852.],\n",
            "        [176702., 170971., 169061., 162852., 162852.],\n",
            "        [170971., 169061., 162852., 162852., 156166.],\n",
            "        [169061., 162852., 162852., 156166., 138974.],\n",
            "        [162852., 162852., 156166., 138974., 139929.],\n",
            "        [162852., 156166., 138974., 139929., 141839.],\n",
            "        [156166., 138974., 139929., 141839., 147092.],\n",
            "        [138974., 139929., 141839., 147092., 148525.],\n",
            "        [139929., 141839., 147092., 148525., 148048.],\n",
            "        [141839., 147092., 148525., 148048., 146137.],\n",
            "        [147092., 148525., 148048., 146137., 146615.],\n",
            "        [148525., 148048., 146137., 146615., 147092.],\n",
            "        [148048., 146137., 146615., 147092., 146137.],\n",
            "        [146137., 146615., 147092., 146137., 148048.],\n",
            "        [146615., 147092., 146137., 148048., 149480.],\n",
            "        [147092., 146137., 148048., 149480., 145660.],\n",
            "        [146137., 148048., 149480., 145660., 144704.],\n",
            "        [148048., 149480., 145660., 144704., 135153.],\n",
            "        [149480., 145660., 144704., 135153., 138496.],\n",
            "        [145660., 144704., 135153., 138496., 149003.],\n",
            "        [144704., 135153., 138496., 149003., 149958.],\n",
            "        [135153., 138496., 149003., 149958., 149958.],\n",
            "        [138496., 149003., 149958., 149958., 149480.],\n",
            "        [149003., 149958., 149958., 149480., 153301.],\n",
            "        [149958., 149958., 149480., 153301., 159987.],\n",
            "        [149958., 149480., 153301., 159987., 156644.],\n",
            "        [149480., 153301., 159987., 156644., 158077.],\n",
            "        [153301., 159987., 156644., 158077., 158554.],\n",
            "        [159987., 156644., 158077., 158554., 157599.],\n",
            "        [156644., 158077., 158554., 157599., 161420.],\n",
            "        [158077., 158554., 157599., 161420., 162852.],\n",
            "        [158554., 157599., 161420., 162852., 163330.],\n",
            "        [157599., 161420., 162852., 163330., 165718.],\n",
            "        [161420., 162852., 163330., 165718., 160942.],\n",
            "        [162852., 163330., 165718., 160942., 167628.],\n",
            "        [163330., 165718., 160942., 167628., 163330.],\n",
            "        [165718., 160942., 167628., 163330., 160942.],\n",
            "        [160942., 167628., 163330., 160942., 159032.],\n",
            "        [167628., 163330., 160942., 159032., 159509.],\n",
            "        [163330., 160942., 159032., 159509., 158554.],\n",
            "        [160942., 159032., 159509., 158554., 156644.],\n",
            "        [159032., 159509., 158554., 156644., 165718.],\n",
            "        [159509., 158554., 156644., 165718., 164763.],\n",
            "        [158554., 156644., 165718., 164763., 165240.],\n",
            "        [156644., 165718., 164763., 165240., 170493.],\n",
            "        [165718., 164763., 165240., 170493., 172404.],\n",
            "        [164763., 165240., 170493., 172404., 172881.],\n",
            "        [165240., 170493., 172404., 172881., 173359.],\n",
            "        [170493., 172404., 172881., 173359., 174314.],\n",
            "        [172404., 172881., 173359., 174314., 175269.],\n",
            "        [172881., 173359., 174314., 175269., 178612.],\n",
            "        [173359., 174314., 175269., 178612., 179567.],\n",
            "        [174314., 175269., 178612., 179567., 173359.],\n",
            "        [175269., 178612., 179567., 173359., 173836.],\n",
            "        [178612., 179567., 173359., 173836., 182910.],\n",
            "        [179567., 173359., 173836., 182910., 187686.],\n",
            "        [173359., 173836., 182910., 187686., 188164.],\n",
            "        [173836., 182910., 187686., 188164., 188164.],\n",
            "        [182910., 187686., 188164., 188164., 191984.],\n",
            "        [187686., 188164., 188164., 191984., 196282.],\n",
            "        [188164., 188164., 191984., 196282., 194850.],\n",
            "        [188164., 191984., 196282., 194850., 191029.],\n",
            "        [191984., 196282., 194850., 191029., 190074.],\n",
            "        [196282., 194850., 191029., 190074., 189596.],\n",
            "        [194850., 191029., 190074., 189596., 188641.],\n",
            "        [191029., 190074., 189596., 188641., 187686.],\n",
            "        [190074., 189596., 188641., 187686., 182433.],\n",
            "        [189596., 188641., 187686., 182433., 179567.],\n",
            "        [188641., 187686., 182433., 179567., 177657.],\n",
            "        [187686., 182433., 179567., 177657., 177179.],\n",
            "        [182433., 179567., 177657., 177179., 172881.],\n",
            "        [179567., 177657., 177179., 172881., 178135.],\n",
            "        [177657., 177179., 172881., 178135., 177657.],\n",
            "        [177179., 172881., 178135., 177657., 178135.],\n",
            "        [172881., 178135., 177657., 178135., 175269.],\n",
            "        [178135., 177657., 178135., 175269., 176224.],\n",
            "        [177657., 178135., 175269., 176224., 169061.],\n",
            "        [178135., 175269., 176224., 169061., 167150.],\n",
            "        [175269., 176224., 169061., 167150., 172881.],\n",
            "        [176224., 169061., 167150., 172881., 171926.],\n",
            "        [169061., 167150., 172881., 171926., 175747.],\n",
            "        [167150., 172881., 171926., 175747., 170493.],\n",
            "        [172881., 171926., 175747., 170493., 166195.],\n",
            "        [171926., 175747., 170493., 166195., 167628.],\n",
            "        [175747., 170493., 166195., 167628., 166673.],\n",
            "        [170493., 166195., 167628., 166673., 163330.],\n",
            "        [166195., 167628., 166673., 163330., 160942.],\n",
            "        [167628., 166673., 163330., 160942., 162375.],\n",
            "        [166673., 163330., 160942., 162375., 160464.],\n",
            "        [163330., 160942., 162375., 160464., 159032.],\n",
            "        [160942., 162375., 160464., 159032., 157121.],\n",
            "        [162375., 160464., 159032., 157121., 163330.],\n",
            "        [160464., 159032., 157121., 163330., 164285.],\n",
            "        [159032., 157121., 163330., 164285., 162375.],\n",
            "        [157121., 163330., 164285., 162375., 170971.],\n",
            "        [163330., 164285., 162375., 170971., 169538.],\n",
            "        [164285., 162375., 170971., 169538., 172404.],\n",
            "        [162375., 170971., 169538., 172404., 173836.],\n",
            "        [170971., 169538., 172404., 173836., 178135.],\n",
            "        [169538., 172404., 173836., 178135., 176702.],\n",
            "        [172404., 173836., 178135., 176702., 181000.],\n",
            "        [173836., 178135., 176702., 181000., 184000.],\n",
            "        [178135., 176702., 181000., 184000., 181000.],\n",
            "        [176702., 181000., 184000., 181000., 180000.],\n",
            "        [181000., 184000., 181000., 180000., 177500.],\n",
            "        [184000., 181000., 180000., 177500., 173000.],\n",
            "        [181000., 180000., 177500., 173000., 178000.],\n",
            "        [180000., 177500., 173000., 178000., 173000.],\n",
            "        [177500., 173000., 178000., 173000., 177000.],\n",
            "        [173000., 178000., 173000., 177000., 177500.],\n",
            "        [178000., 173000., 177000., 177500., 179500.],\n",
            "        [173000., 177000., 177500., 179500., 178000.],\n",
            "        [177000., 177500., 179500., 178000., 176500.],\n",
            "        [177500., 179500., 178000., 176500., 180500.],\n",
            "        [179500., 178000., 176500., 180500., 175000.],\n",
            "        [178000., 176500., 180500., 175000., 172500.],\n",
            "        [176500., 180500., 175000., 172500., 172500.],\n",
            "        [180500., 175000., 172500., 172500., 176500.],\n",
            "        [175000., 172500., 172500., 176500., 175500.],\n",
            "        [172500., 172500., 176500., 175500., 170500.],\n",
            "        [172500., 176500., 175500., 170500., 171000.],\n",
            "        [176500., 175500., 170500., 171000., 167000.]], device='cuda:0')]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}