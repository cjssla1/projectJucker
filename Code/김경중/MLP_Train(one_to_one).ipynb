{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Train(one to one).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdCwjeUdpuJGO1ymTUojkt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx04U5ab9uaC",
        "colab_type": "code",
        "outputId": "6daea55d-b867-461b-c912-5cf5416d9b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "#파이토치 인스톨\n",
        "!pip install torch torchvision\n",
        "!pip install -U finance-datareader\n",
        "import FinanceDataReader as fdr\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "from copy import deepcopy # Add Deepcopy for args\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already up-to-date: finance-datareader in /usr/local/lib/python3.6/dist-packages (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: requests-file in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from requests-file->finance-datareader) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYjn1Z4e96kx",
        "colab_type": "code",
        "outputId": "a2598a1f-c102-4226-ca43-f575581aeee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%matplotlib inline\n",
        "#데이터 생성과 화면 표시를 위한 라이브러리 호출\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "#실험결과 비교를 위해 시드 고정\n",
        "seed = 444\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f39681dd9f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuXOQqXuBeVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class stockDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, symbol, x_frames, y_frames):\n",
        "        \n",
        "        self.symbol = symbol\n",
        "        self.x_frames = x_frames\n",
        "        self.y_frames = y_frames\n",
        "        \n",
        "        self.start = datetime.datetime.now() - datetime.timedelta(days=(x_frames+y_frames)*2+10)\n",
        "        self.end = datetime.date.today()\n",
        "        self.data = fdr.DataReader(self.symbol, self.start, self.end)\n",
        "        self.data = self.data.tail(x_frames+y_frames)\n",
        "        print(self.data.isna().sum())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        idx += self.x_frames\n",
        "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
        "        data = data[['High', 'Low', 'Open', 'Close', 'Change', 'Volume']]\n",
        "        data = data.apply(lambda x: (x+1) / (x[self.x_frames-1]+1))\n",
        "        data = data.values\n",
        "        X = data[:self.x_frames]\n",
        "        y = data[self.x_frames:]\n",
        "        \n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXbe3OHNAc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StockDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, symbol, x_frames, y_frames, start, end):\n",
        "        \n",
        "        self.symbol = symbol\n",
        "        self.x_frames = x_frames\n",
        "        self.y_frames = y_frames\n",
        "        \n",
        "        self.start = datetime.datetime(*start)\n",
        "        self.end = datetime.datetime(*end)\n",
        "\n",
        "        self.data = fdr.DataReader(self.symbol, self.start, self.end)\n",
        "        print(self.data.isna().sum())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        idx += self.x_frames\n",
        "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
        "        data = data[['High', 'Low', 'Open', 'Close', 'Change', 'Volume']]\n",
        "        if self.x_frames > 1:\n",
        "            data = data.apply(lambda x: (x+1) / (x[self.x_frames-1]+1))\n",
        "        data = data.values\n",
        "        X = data[:self.x_frames]\n",
        "        y = data[self.x_frames:]\n",
        "        \n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8qxu117W9cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 정의\n",
        "    \n",
        "class MLPModel(nn.Module):\n",
        "    # input = 입력값 개수, output = 출력값 개수\n",
        "    def __init__(self,_input,_output,_hidden_layers): \n",
        "        super(MLPModel, self).__init__()\n",
        "        self.inputv = _input\n",
        "        self.outputv = _output\n",
        "        nodes = [_input] + _hidden_layers + [_output]\n",
        "        self.depth = len(nodes)\n",
        "        linears = [nn.Linear(nodes[i], nodes[i+1]) for i in range(self.depth-1)]\n",
        "        self.linears = nn.ModuleList(linears)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "    # 인스턴스(샘플) x가 인풋으로 들어왔을 때 모델이 예측하는 y값을 리턴합니다.\n",
        "        for linear in self.linears[:-1]: \n",
        "          x = linear(x)\n",
        "          x = self.relu(x)\n",
        "        x = self.linears[-1](x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCWllGDKzDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#trainloader = torch.cat(trainloader).view(len(trainloader), batch_size, -1)\n",
        "def train(model, trainset, optimizer, loss_fn,device):\n",
        "    trainloader = DataLoader(trainset, shuffle=True, drop_last=True)\n",
        "\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "\n",
        "        X = X.float().to(device)\n",
        "        y_true = y[:, :, 3].float().to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    return model, train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS8T4O1afl8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, valset, loss_fn,device):\n",
        "    valloader = DataLoader(valset, shuffle=False, drop_last=True)\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(valloader):\n",
        "\n",
        "            X = X.float().to(device)\n",
        "            y_true = y[:, :, 3].float().to(device)\n",
        "\n",
        "            y_pred = model(X)\n",
        "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss = val_loss / len(valloader)\n",
        "    return val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srOp6JjQN1Q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c52f0d80-0bc9-4635-dac7-aa12e85291ee"
      },
      "source": [
        "trainset = StockDataset('001040',1,1,(2018,5,1),(2020,5,20))\n",
        "valset = StockDataset('005930',1,1,(2018,5,1),(2020,5,20))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Change    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqgLAlGPBwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "dddcb7c6-a991-4b22-be8a-5a04af71ded3"
      },
      "source": [
        "batch_size = 1\n",
        "input_dim = 6\n",
        "hidden_dim = 50\n",
        "output_dim = 1\n",
        "layers = [200,100,50,25,15,10,5]\n",
        "epoch = 5\n",
        "\n",
        "model = MLPModel(input_dim,output_dim,layers)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPModel(\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=6, out_features=200, bias=True)\n",
              "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
              "    (3): Linear(in_features=50, out_features=25, bias=True)\n",
              "    (4): Linear(in_features=25, out_features=15, bias=True)\n",
              "    (5): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (6): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (7): Linear(in_features=5, out_features=1, bias=True)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PL7AhfyPjkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "cbdf1d07-1543-4a54-ac90-2e44f57a317d"
      },
      "source": [
        "for e in range(epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        model, train_loss = train(model, trainset ,optimizer, loss_fn,device)\n",
        "        val_loss = validate(model, valset, loss_fn,device)\n",
        "        te = time.time()\n",
        "\n",
        "        print('Epoch {}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'.format(e, train_loss, val_loss, te-ts))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss(train/val) 29566945.87945/97775849349.36526. Took 5.29 sec\n",
            "Epoch 1, Loss(train/val) 41457081.24269/86541063448.01596. Took 5.28 sec\n",
            "Epoch 2, Loss(train/val) 42276866.41932/183062439799.56885. Took 5.35 sec\n",
            "Epoch 3, Loss(train/val) 25325832.06746/128557767240.55888. Took 5.35 sec\n",
            "Epoch 4, Loss(train/val) 28590185.51858/108065834625.27745. Took 5.34 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYZEB6mrFOif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class epochClass():\n",
        "\n",
        "    def __init__(self,_model,_optimizer,_device):\n",
        "        self.model = _model\n",
        "        self.optimizer = _optimizer\n",
        "        self.reg_loss = nn.MSELoss()\n",
        "        self.device = _device\n",
        "        self.list_epoch = []\n",
        "        self.list_val_loss = []\n",
        "        self.list_mae = []\n",
        "        self.list_mae_epoch = []\n",
        "\n",
        "    def getModelOptim(self):\n",
        "        return self.model, self.optimizer\n",
        "\n",
        "    def getEpochList(self):\n",
        "        return self.list_epoch, self.list_val_loss, self.list_mae, self.list_mae_epoch\n",
        "\n",
        "    def startEpoch(self,epoch,interval,train_X,train_y,val_X,val_y,test_X,test_y):\n",
        "    \n",
        "\n",
        "        for i in range(epoch):    \n",
        "            # ====== Train ====== #\n",
        "            self.model.train() # model을 train 모드로 세팅합니다. 반대로 향후 모델을 평가할 때는 eval() 모드로 변경할 겁니다 \n",
        "            self.optimizer.zero_grad() # optimizer에 남아있을 수도 있는 잔여 그라디언트를 0으로 다 초기화해줍니다.\n",
        "            \n",
        "            input_x = torch.Tensor(train_X)\n",
        "            true_y = torch.Tensor(train_y)\n",
        "            #Gpu로 데이터 옮기기\n",
        "            input_x = input_x.to(device)\n",
        "            true_y = true_y.to(device)\n",
        "            #\n",
        "            pred_y = self.model(input_x)\n",
        "            #\n",
        "            \n",
        "            loss = self.reg_loss(pred_y.squeeze(), true_y)\n",
        "            loss.backward() # backward()를 통해서 그라디언트를 구해줍니다.\n",
        "            self.optimizer.step() # step()을 통해서 그라디언틀르 바탕으로 파라미터를 업데이트 해줍니다. \n",
        "            self.list_epoch.append(i)\n",
        "            \n",
        "            # ====== Validation ====== #\n",
        "            self.model.eval()\n",
        "            self.optimizer.zero_grad()\n",
        "            input_x = torch.Tensor(val_X)\n",
        "            true_y = torch.Tensor(val_y)\n",
        "            #GPU로 데이터 옮기기\n",
        "            input_x = input_x.to(device)\n",
        "            true_y = true_y.to(device)\n",
        "            #\n",
        "            pred_y = self.model(input_x)   \n",
        "            loss = self.reg_loss(pred_y.squeeze(), true_y)\n",
        "            self.list_val_loss.append(loss.item())\n",
        "            \n",
        "\n",
        "            # ====== Evaluation ======= #\n",
        "            if i % interval == 0: # 200회의 학습마다 실제 데이터 분포와 모델이 예측한 분포를 그려봅니다.\n",
        "                \n",
        "                # ====== Calculate MAE ====== #\n",
        "                self.model.eval()\n",
        "                self.optimizer.zero_grad()\n",
        "                input_x = torch.Tensor(test_X)\n",
        "                true_y = torch.Tensor(test_y)\n",
        "                #\n",
        "                input_x = input_x.to(device)\n",
        "                true_y = true_y.to(device)\n",
        "                #\n",
        "                pred_y = self.model(input_x)\n",
        "                mae = self.reg_loss(true_y, pred_y.squeeze())\n",
        "                self.list_mae.append(mae)\n",
        "                self.list_mae_epoch.append(i)\n",
        "                \n",
        "                print(i, mae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slENN0UDXQFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5f7c6a4f-75f6-4cb2-cafa-0f997589e649"
      },
      "source": [
        "'''\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# 학습에 필요한 파라미터 정의\n",
        "\n",
        "model = MLPModel(15,1,[200,150,100,50,25,10]) # Model을 생성해줍니다.\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "#modelPath = '/content/gdrive/My Drive/model.pt'\n",
        "#model.load_state_dict(torch.load(modelPath))\n",
        "# ===== Construct Optimizer ====== #\n",
        "lr = 0.005 # Learning Rate를 하나 정해줍니다. (원할한 학습을 위해 손을 많이 탑니다)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr) # Optimizer를 생성해줍니다.\n",
        "'''"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport torch.optim as optim\\nfrom sklearn.metrics import mean_absolute_error\\n# 학습에 필요한 파라미터 정의\\n\\nmodel = MLPModel(15,1,[200,150,100,50,25,10]) # Model을 생성해줍니다.\\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\\nmodel = model.to(device)\\n#modelPath = '/content/gdrive/My Drive/model.pt'\\n#model.load_state_dict(torch.load(modelPath))\\n# ===== Construct Optimizer ====== #\\nlr = 0.005 # Learning Rate를 하나 정해줍니다. (원할한 학습을 위해 손을 많이 탑니다)\\noptimizer = optim.Adam(model.parameters(), lr=lr) # Optimizer를 생성해줍니다.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OAz78sNJHsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습 시작\n",
        "#ep = epochClass(model,optimizer,device)\n",
        "#ep.startEpoch(4000,200,train_X,train_y,val_X,val_y,test_X,test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOXSCikiga8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습결과 차트로 보여주기\n",
        "#list_epoch,list_val_loss,list_mae,list_mae_epoch = ep.getEpochList()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OANyPaziXbLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class pltClass():\n",
        "\n",
        "    def __init__(self,_list_epoch, _list_val_loss, _list_mae_epoch, _list_mae):\n",
        "        self.list_epoch = _list_epoch\n",
        "        self.list_val_loss = _list_val_loss\n",
        "        self.list_mae_epoch = _list_mae_epoch\n",
        "        self.list_mae = _list_mae\n",
        "\n",
        "\n",
        "    def printFigure(self):\n",
        "        fig = plt.figure(figsize=(24,5))\n",
        "\n",
        "\n",
        "        # ====== valid plot ====== #\n",
        "        ax2 = fig.add_subplot(1, 2, 1)\n",
        "        ax2.plot(self.list_epoch, self.list_val_loss, '--', label='val')\n",
        "        ax2.set_xlabel('epoch')\n",
        "        ax2.set_ylabel('loss')\n",
        "        #ax1.set_ylim(0, 5)\n",
        "        ax2.grid()\n",
        "        ax2.legend()\n",
        "        ax2.set_title('epoch vs loss')\n",
        "\n",
        "        # ====== test plot ====== #\n",
        "        ax3 = fig.add_subplot(1, 2, 2)\n",
        "        ax3.plot(self.list_mae_epoch, self.list_mae, marker='x', label='test')\n",
        "\n",
        "        ax3.set_xlabel('epoch')\n",
        "        ax3.set_ylabel('mae')\n",
        "        ax3.grid()\n",
        "        ax3.legend()\n",
        "        ax3.set_title('epoch vs loss')\n",
        "\n",
        "\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egasKQaTrHJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#pltc = pltClass(list_epoch,list_val_loss,list_mae_epoch,list_mae)\n",
        "#pltc.printFigure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evdZZfvlBPOl",
        "colab_type": "code",
        "outputId": "fa89c5f6-9548-4f5f-8822-132b8a34f52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "prediction = model(torch.Tensor(test_X))\n",
        "pred = []\n",
        "real = test_y\n",
        "for i in prediction[:].T:\n",
        "    for j in i:\n",
        "        pred.append(j.item())\n",
        "\n",
        "print(real)\n",
        "print(pred)\n",
        "'''"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"model.to('cpu')\\nmodel.eval()\\n\\nprediction = model(torch.Tensor(test_X))\\npred = []\\nreal = test_y\\nfor i in prediction[:].T:\\n    for j in i:\\n        pred.append(j.item())\\n\\nprint(real)\\nprint(pred)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRUkytQIntur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelPath = '/content/gdrive/My Drive/model.pt'\n",
        "#torch.save(model.state_dict(), modelPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-LdVdn_ThcK",
        "colab_type": "code",
        "outputId": "8a61e7da-b08f-4d7d-ea7c-074c7b0d419e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''fig = plt.figure(figsize=(20,10))\n",
        "xl = [n for n in range(1,len(pred)+1)]\n",
        "\n",
        "# ====== valid plot ====== #\n",
        "ax2 = fig.add_subplot(1, 1, 1)\n",
        "ax2.plot(xl, pred, 'o', label='pred')\n",
        "ax2.plot(xl, real, 'x', label='real')\n",
        "ax2.set_xlabel('len')\n",
        "ax2.set_ylabel('value')\n",
        "#ax1.set_ylim(0, 5)\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "ax2.set_title('pred vs real')\n",
        "'''"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"fig = plt.figure(figsize=(20,10))\\nxl = [n for n in range(1,len(pred)+1)]\\n\\n# ====== valid plot ====== #\\nax2 = fig.add_subplot(1, 1, 1)\\nax2.plot(xl, pred, 'o', label='pred')\\nax2.plot(xl, real, 'x', label='real')\\nax2.set_xlabel('len')\\nax2.set_ylabel('value')\\n#ax1.set_ylim(0, 5)\\nax2.grid()\\nax2.legend()\\nax2.set_title('pred vs real')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}